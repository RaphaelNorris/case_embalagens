# ğŸ“¦ Case Embalagens - ADAMI Production Optimization

<p align="center">
  <img src="./lifecycle_ml.png" alt="ML Lifecycle" width="800"/>
</p>

<p align="center">
  <a href="https://github.com/RaphaelNorris/case_embalagens/actions/workflows/ci.yml">
    <img src="https://github.com/RaphaelNorris/case_embalagens/actions/workflows/ci.yml/badge.svg" alt="CI">
  </a>
  <a href="https://www.python.org/downloads/">
    <img src="https://img.shields.io/badge/python-3.11+-blue.svg" alt="Python 3.11+">
  </a>
  <a href="https://github.com/astral-sh/ruff">
    <img src="https://img.shields.io/badge/code%20style-ruff-000000.svg" alt="Ruff">
  </a>
  <a href="https://github.com/RaphaelNorris/case_embalagens">
    <img src="https://img.shields.io/badge/version-2.3.0-green.svg" alt="Version 2.3.0">
  </a>
  <a href="https://www.docker.com/">
    <img src="https://img.shields.io/badge/docker-ready-blue.svg" alt="Docker Ready">
  </a>
</p>

---

## ğŸ“‹ VisÃ£o Geral

Projeto de **otimizaÃ§Ã£o de processos de produÃ§Ã£o** para ADAMI (indÃºstria de embalagens) em parceria com AMCOM.

Implementa um **pipeline completo de Machine Learning** seguindo metodologias **CRISP-DM** e **CD4ML** (Continuous Delivery for Machine Learning), com foco em **produtividade**, **qualidade de cÃ³digo** e **deploy automatizado**.

### ğŸ¯ Objetivos Principais

- ğŸ“Š **AnÃ¡lise de Paradas de MÃ¡quinas**: Identificar padrÃµes e causas de paradas nÃ£o programadas
- ğŸš€ **OtimizaÃ§Ã£o de ProduÃ§Ã£o**: Prever tempo de produÃ§Ã£o (mÂ³/h) e otimizar alocaÃ§Ã£o de recursos
- ğŸ”ª **GestÃ£o de Facas/LÃ¢minas**: Monitorar ciclo de vida e performance de ferramentas de corte
- ğŸ“ˆ **Analytics em Tempo Real**: Dashboard Streamlit para visualizaÃ§Ã£o de KPIs de produÃ§Ã£o
- ğŸ¤– **ML em ProduÃ§Ã£o**: InferÃªncia automatizada com Docker e testes completos

### âœ¨ Destaques TÃ©cnicos (v2.3.0)

- âœ… **100% Logger Estruturado** - Zero prints em produÃ§Ã£o
- âœ… **Docker Production-Ready** - Multi-stage, otimizado (<400MB)
- âœ… **40% Cobertura de Testes** - Testes automatizados com pytest
- âœ… **DRY Architecture** - Zero duplicaÃ§Ã£o de cÃ³digo
- âœ… **FTI Pipelines** - Feature/Training/Inference separados
- âœ… **Medallion Architecture** - Bronze/Silver/Gold data layers

---

## ğŸ—ï¸ Arquitetura do Projeto

```
case_embalagens/
â”œâ”€â”€ ğŸ³ Dockerfile                    # Container production-ready
â”œâ”€â”€ ğŸ³ docker-compose.yml            # OrchestraÃ§Ã£o (inference, training, dashboard)
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ Makefile                        # Comandos de automaÃ§Ã£o
â”œâ”€â”€ .pre-commit-config.yaml         # Quality hooks
â”œâ”€â”€ .env.example                    # Template de variÃ¡veis
â”‚
â”œâ”€â”€ ğŸ“ project_data_science/        # Projeto principal de Data Science
â”‚   â”œâ”€â”€ ğŸ“Š data/
â”‚   â”‚   â”œâ”€â”€ 01 - raw/              # ğŸ¥‰ Bronze: Dados brutos
â”‚   â”‚   â”œâ”€â”€ 02 - trusted/          # ğŸ¥ˆ Silver: Dados limpos
â”‚   â”‚   â”œâ”€â”€ 03 - ml/               # ğŸ¤– ML: Features engineeradas
â”‚   â”‚   â””â”€â”€ 04 - refined/          # ğŸ¥‡ Gold: Dados analÃ­ticos
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“š docs/                   # DocumentaÃ§Ã£o completa
â”‚   â”‚   â”œâ”€â”€ POC_TO_PRODUCTION.md   # Guia de transiÃ§Ã£o POCâ†’Prod
â”‚   â”‚   â”œâ”€â”€ NOTEBOOKS_REORGANIZATION.md
â”‚   â”‚   â”œâ”€â”€ PRODUCTION_IMPROVEMENTS.md # v2.3.0 melhorias
â”‚   â”‚   â””â”€â”€ data_quality/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ““ notebooks/              # Jupyter notebooks (POC/Experimentos)
â”‚   â”‚   â”œâ”€â”€ 01-eda-tables/        # EDA por tabela
â”‚   â”‚   â”œâ”€â”€ 02-eda-cross/         # AnÃ¡lises cruzadas
â”‚   â”‚   â”œâ”€â”€ 03-preprocessing/     # Feature engineering
â”‚   â”‚   â”œâ”€â”€ 04-production/        # Notebooks produÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ 05-data-loading/      # ETL notebooks
â”‚   â”‚   â””â”€â”€ experiments/          # Experimentos ML
â”‚   â”‚       â”œâ”€â”€ clustering/       # GMM, segmentaÃ§Ã£o
â”‚   â”‚       â””â”€â”€ ds-pipelines/     # Pipelines completos
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ src/                   # CÃ³digo fonte (PRODUÃ‡ÃƒO)
â”‚   â”‚   â”œâ”€â”€ config.py             # âš™ï¸ Config centralizado (Pydantic)
â”‚   â”‚   â”œâ”€â”€ config_manager.py     # ğŸ›ï¸ Manager de paths
â”‚   â”‚   â”œâ”€â”€ logger.py             # ğŸ“ Logger estruturado (Loguru)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ’¾ data/              # MÃ³dulos de dados
â”‚   â”‚   â”‚   â”œâ”€â”€ conn_oracle.py
â”‚   â”‚   â”‚   â”œâ”€â”€ conn_sql.py
â”‚   â”‚   â”‚   â””â”€â”€ data_quality_*.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ¤– ml_artifacts/      # PersistÃªncia de modelos
â”‚   â”‚   â”‚   â”œâ”€â”€ model_persistence.py
â”‚   â”‚   â”‚   â””â”€â”€ example_load_and_predict.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“Š viz/               # VisualizaÃ§Ãµes (Plotly)
â”‚   â”‚   â”‚   â””â”€â”€ plots.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ¨ dashboards/        # Streamlit apps
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard_facas.py
â”‚   â”‚   â”‚   â””â”€â”€ dashboard_main.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“± app/               # App Streamlit principal
â”‚   â”‚   â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_analyzer.py
â”‚   â”‚   â”‚   â””â”€â”€ openai_insights.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ”„ pipelines/         # Pipelines ML
â”‚   â”‚       â”œâ”€â”€ shared/           # ğŸ†• CÃ³digo compartilhado (DRY)
â”‚   â”‚       â”‚   â””â”€â”€ preprocessing.py  # Classes reutilizÃ¡veis
â”‚   â”‚       â”œâ”€â”€ feature/          # Feature engineering
â”‚   â”‚       â”œâ”€â”€ training/         # Model training
â”‚   â”‚       â”œâ”€â”€ inference/        # Predictions
â”‚   â”‚       â””â”€â”€ DS/               # Core pipeline logic
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§ª tests/                 # Testes automatizados (40% coverage)
â”‚   â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”‚   â””â”€â”€ test_preprocessing.py  # 23 testes
â”‚   â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ test_model_persistence.py  # 18 testes
â”‚   â”‚   â”œâ”€â”€ test_features.py
â”‚   â”‚   â””â”€â”€ test_config.py
â”‚   â”‚
â”‚   â””â”€â”€ pyproject.toml            # Config do projeto
â”‚
â””â”€â”€ ğŸ“ project_data_engineer/     # Pipeline de dados (Airflow)
    â””â”€â”€ dags/                     # DAGs de orquestraÃ§Ã£o
```

---

## ğŸš€ Quick Start

### OpÃ§Ã£o 1: Docker (Recomendado para ProduÃ§Ã£o) ğŸ³

```bash
# Clone o repositÃ³rio
git clone https://github.com/RaphaelNorris/case_embalagens.git
cd case_embalagens

# Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas credenciais

# Build da imagem
docker-compose build

# Executar serviÃ§o de inferÃªncia
docker-compose up -d inference

# Ver logs
docker-compose logs -f inference

# Treinar modelos (one-time job)
docker-compose --profile training up training

# Dashboard Streamlit
docker-compose --profile dashboard up -d dashboard
```

**Acesse o dashboard**: http://localhost:8501

### OpÃ§Ã£o 2: Desenvolvimento Local ğŸ’»

```bash
# PrÃ©-requisitos
# - Python 3.11+
# - Oracle Client (para conexÃµes Oracle)
# - ODBC Driver for SQL Server

# Clone o repositÃ³rio
git clone https://github.com/RaphaelNorris/case_embalagens.git
cd case_embalagens

# Configure variÃ¡veis de ambiente
cp .env.example .env

# Instale dependÃªncias
make install-dev

# Configure pre-commit hooks
pre-commit install

# Execute testes
make test

# Execute app Streamlit
make app-facas
```

---

## ğŸ“Š Camadas de Dados (Medallion Architecture)

### ğŸ¥‰ Bronze Layer (`01 - raw/`)
**Dados brutos** extraÃ­dos diretamente das fontes sem transformaÃ§Ãµes.

### ğŸ¥ˆ Silver Layer (`02 - trusted/`)
**Dados limpos**, padronizados e validados.

**Principais tabelas**:
- `tb_clientes.parquet` - InformaÃ§Ãµes de clientes
- `tb_pedidos.parquet` - Ordens de produÃ§Ã£o
- `tb_itens.parquet` - Itens dos pedidos
- `tb_maquinas.parquet` - Dados das mÃ¡quinas (CV, Flexo)
- `tb_facas.parquet` - Facas/lÃ¢minas de corte
- `tb_paradas.parquet` - Eventos de parada
- `tb_tarefcon.parquet` - Controle de tarefas

### ğŸ¥‡ Gold Layer (`04 - refined/`)
**Dados agregados** e prontos para anÃ¡lise/BI.

### ğŸ¤– ML Layer (`03 - ml/`)
**Features engineeradas** prontas para treinamento.

---

## ğŸ”§ Principais Funcionalidades

### 1ï¸âƒ£ ConexÃµes de Banco de Dados

```python
from src.data.conn_oracle import oracle_connection
from src.data.conn_sql import sqlserver_connection

# Oracle (com context manager)
with oracle_connection('trusted') as conn:
    df = pd.read_sql("SELECT * FROM tb_pedidos", conn)

# SQL Server
with sqlserver_connection() as conn:
    df = pd.read_sql("SELECT * FROM dbo.Clientes", conn)
```

### 2ï¸âƒ£ Preprocessing com DRY Architecture ğŸ†•

```python
from src.pipelines.shared import TrainingPreprocessor, InferencePreprocessor

# TREINO: Filtros estritos para dados limpos
prep = TrainingPreprocessor(delivery_date_cutoff='2024-01-01')
df_train = prep.preprocess(df_raw)

# INFERÃŠNCIA: Aceita todos os dados de produÃ§Ã£o
prep = InferencePreprocessor()
df_pred = prep.preprocess(df_new)
```

### 3ï¸âƒ£ Logger Estruturado ğŸ†•

```python
from src.logger import get_logger

logger = get_logger(__name__)

logger.info("Processando pedidos", extra={"count": len(df)})
logger.warning("Dados incompletos", extra={"missing_cols": cols})
logger.error("Erro no modelo", extra={"error": str(e)})
```

### 4ï¸âƒ£ PersistÃªncia de Modelos

```python
from src.ml_artifacts.model_persistence import save_model_artifacts, load_model_artifacts

# Salvar modelo
save_model_artifacts(
    model=trained_model,
    model_path=Path("models/flexo_v1.pkl"),
    selected_features=feature_names,
    model_type='catboost',
    task_type='regression'
)

# Carregar modelo
artifacts = load_model_artifacts(Path("models/flexo_v1.pkl"))
predictions = artifacts['model'].predict(X_new)
```

### 5ï¸âƒ£ Dashboard Streamlit

```bash
# Com Docker
docker-compose --profile dashboard up -d dashboard

# Local
cd project_data_science/src/app
streamlit run streamlit_app.py
```

---

## ğŸ§ª Testes (40% Coverage)

```bash
# Todos os testes
pytest

# Com coverage report
pytest --cov=src --cov-report=html

# Abrir relatÃ³rio HTML
open htmlcov/index.html

# Testes especÃ­ficos
pytest tests/shared/test_preprocessing.py -v

# Testes rÃ¡pidos apenas
pytest -m "not slow"
```

**Testes implementados**:
- âœ… 23 testes de preprocessing (TrainingPreprocessor, InferencePreprocessor)
- âœ… 18 testes de model persistence (save/load)
- âœ… Testes de integraÃ§Ã£o
- âœ… Performance tests

---

## ğŸ³ Docker

### Services DisponÃ­veis

| Service | DescriÃ§Ã£o | Port | Profile |
|---------|-----------|------|---------|
| **inference** | PrediÃ§Ãµes batch | - | default |
| **training** | Treino de modelos | - | training |
| **dashboard** | Streamlit UI | 8501 | dashboard |

### Comandos Docker

```bash
# Build
docker-compose build

# Inference (sempre rodando)
docker-compose up -d inference

# Training (one-time)
docker-compose --profile training up training

# Dashboard
docker-compose --profile dashboard up -d dashboard

# Ver logs
docker-compose logs -f [service_name]

# Stop tudo
docker-compose down

# Rebuild completo
docker-compose build --no-cache
```

---

## ğŸ“ Estrutura de Notebooks

ConvenÃ§Ã£o de nomenclatura:

```
XX.Y-rn-tipo-contexto-YYYYMMDD.ipynb
```

**Exemplo**: `21.0-rn-preprocessing-itens-20240101.ipynb`

### Categorias de Notebooks

| Range | Categoria | DescriÃ§Ã£o |
|-------|-----------|-----------|
| **00-09** | EDA Tables | AnÃ¡lise exploratÃ³ria individual |
| **10-19** | EDA Cross | AnÃ¡lises cruzadas e relacionamentos |
| **20-29** | Preprocessing | Feature engineering e limpeza |
| **30-39** | Production | Notebooks prontos para produÃ§Ã£o |
| **40-49** | Clustering | Experimentos de clusterizaÃ§Ã£o (GMM) |
| **50-59** | Pipelines | Pipelines ML completos (CV, Flexo) |

---

## ğŸ” Qualidade de CÃ³digo

### Ferramentas

- âœ… **Ruff**: Linting e formataÃ§Ã£o ultrarrÃ¡pida
- âœ… **MyPy**: Type checking estÃ¡tico
- âœ… **Pytest**: Framework de testes (40% coverage)
- âœ… **Pre-commit**: Hooks automÃ¡ticos
- âœ… **Loguru**: Logger estruturado
- âœ… **Pydantic**: ValidaÃ§Ã£o de configuraÃ§Ãµes

### Comandos

```bash
# Formatar cÃ³digo
make format

# Linting
make lint

# Type checking
make mypy

# Executar tudo
make qa
```

---

## ğŸ“š DocumentaÃ§Ã£o

DocumentaÃ§Ã£o completa em `project_data_science/docs/`:

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| **POC_TO_PRODUCTION.md** | Guia de transiÃ§Ã£o POC â†’ ProduÃ§Ã£o (v2.1.0) |
| **NOTEBOOKS_REORGANIZATION.md** | ReorganizaÃ§Ã£o de notebooks (v2.2.0) |
| **PRODUCTION_IMPROVEMENTS.md** | Melhorias crÃ­ticas (v2.3.0) |
| **PROJECT_STRUCTURE.md** | Estrutura detalhada do projeto |

---

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core ML & Data
- **Pandas, NumPy** - ManipulaÃ§Ã£o de dados
- **Scikit-learn** - ML clÃ¡ssico
- **XGBoost, CatBoost, LightGBM** - Gradient boosting
- **Statsmodels** - AnÃ¡lise estatÃ­stica
- **Streamlit** - Dashboards interativos
- **Plotly** - VisualizaÃ§Ãµes

### Databases
- **Oracle DB** - Banco principal (oracledb)
- **SQL Server** - Analytics (pyodbc)

### MLOps & DevOps
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o
- **Airflow** - OrquestraÃ§Ã£o de pipelines
- **GitHub Actions** - CI/CD
- **Pre-commit** - Quality hooks
- **Pytest** - Testing framework
- **Loguru** - Structured logging
- **Pydantic** - Config management

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'feat: Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### ConvenÃ§Ãµes de CÃ³digo

- âœ… Seguir PEP 8 (via Ruff)
- âœ… Type hints em funÃ§Ãµes pÃºblicas
- âœ… Docstrings no formato Google
- âœ… Logger estruturado (sem `print()`)
- âœ… Testes para novas funcionalidades
- âœ… DRY (Don't Repeat Yourself)

### Commits SemÃ¢nticos

```
feat: Nova funcionalidade
fix: CorreÃ§Ã£o de bug
refactor: RefatoraÃ§Ã£o de cÃ³digo
docs: AtualizaÃ§Ã£o de documentaÃ§Ã£o
test: AdiÃ§Ã£o/correÃ§Ã£o de testes
chore: Tarefas de manutenÃ§Ã£o
```

---

## ğŸ“ˆ Roadmap

### âœ… ConcluÃ­do (v2.3.0)
- [x] Logger estruturado (0 prints)
- [x] DRY preprocessing classes
- [x] Docker production-ready
- [x] Testes essenciais (40% coverage)
- [x] DocumentaÃ§Ã£o completa

### ğŸ”„ Em Andamento
- [ ] Aumentar cobertura de testes para 70%
- [ ] MLflow experiment tracking
- [ ] Data validation (Pandera/Great Expectations)

### ğŸ“‹ PrÃ³ximos Passos
- [ ] API FastAPI para inferÃªncia
- [ ] Feature Store (Feast)
- [ ] Monitoramento de drift
- [ ] Deploy Kubernetes
- [ ] Observabilidade (Prometheus, Grafana)

---

## ğŸ” SeguranÃ§a

- âœ… Credenciais via variÃ¡veis de ambiente (.env)
- âœ… `.gitignore` para dados sensÃ­veis
- âœ… Pre-commit hook para detecÃ§Ã£o de secrets
- âœ… ValidaÃ§Ã£o de dados com Pydantic
- âœ… Docker non-root user
- âœ… Health checks em containers

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© propriedade de **ADAMI** em parceria com **AMCOM**.

---

## ğŸ‘¥ Autores

- **Raphael Norris** - *Data Science Lead*

---

## ğŸ™ Agradecimentos

- **ADAMI** - Dados e expertise de domÃ­nio
- **AMCOM** - Parceria tecnolÃ³gica

---

<p align="center">
  <strong>Desenvolvido com â¤ï¸ para otimizaÃ§Ã£o de processos industriais</strong>
</p>

<p align="center">
  <sub>VersÃ£o 2.3.0 | Production Ready ğŸš€</sub>
</p>
