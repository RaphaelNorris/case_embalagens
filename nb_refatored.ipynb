{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto: Associa√ß√£o Temporal de Paradas e OPs\n",
    "\n",
    "Este notebook organiza o pipeline para:\n",
    "\n",
    "1. Padronizar chaves (preencher `CD_PEDIDO` e `CD_ITEM` a partir de `CD_OP`).\n",
    "2. Ordenar temporalmente os eventos por m√°quina, com diagn√≥sticos de monotonicidade.\n",
    "3. Associar paradas entre ajustes consecutivos.\n",
    "4. Inferir OP faltante via merge temporal (`asof`).\n",
    "5. Marcar eventos pr√≥ximos √†s trocas de turno.\n",
    "\n",
    "---\n",
    "## üìå Cita√ß√µes do Cliente\n",
    "\n",
    "> *‚ÄúExatamente. N√£o existe uma associa√ß√£o direta entre evento de Parada e evento de Produ√ß√£o. O sistema basicamente conta chapas e registra eventos de parada.‚Äù*\n",
    "\n",
    "> *‚ÄúToda vez que um evento √© classificado como Ajuste (c√≥d. 1) o operador informa ao sistema qual ser√° a pr√≥xima ordem e automaticamente o sistema encerra a ordem anterior; todas as paradas que estiverem dentro do per√≠odo entre 2 eventos de Ajuste s√£o automaticamente classificadas como pertencentes √†quela OP anterior.‚Äù*\n",
    "\n",
    "> *‚ÄúAcredito que sejam apontamentos indevidos‚Ä¶ Verifique se estes eventos n√£o est√£o com hor√°rios relacionados √†s trocas de turno (~05:00; 13:00; 21:00).‚Äù*\n",
    "\n",
    "---\n",
    "## ‚úÖ Vamos implementar todo o pipeline abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MISSING_TOKENS = {\"\", \"-1\", \"None\", \"nan\"}\n",
    "\n",
    "def is_missing_str(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    return s.isna() | s.str.strip().isin(MISSING_TOKENS)\n",
    "\n",
    "def normalize_datetimes(df, cini=\"DT_INICIO\", cfim=\"DT_FIM\"):\n",
    "    df = df.copy()\n",
    "    df[cini] = pd.to_datetime(df[cini], errors='coerce')\n",
    "    df[cfim] = pd.to_datetime(df[cfim], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def split_op_into_cols(df, op_col=\"CD_OP\", ped_col=\"CD_PEDIDO\", item_col=\"CD_ITEM\"):\n",
    "    df = df.copy()\n",
    "    df[ped_col] = df.get(ped_col, pd.NA)\n",
    "    df[item_col] = df.get(item_col, pd.NA)\n",
    "\n",
    "    op_str = df[op_col].astype(\"string\").str.strip()\n",
    "    mask = op_str.str.contains(\"/\") & ~op_str.isin(MISSING_TOKENS)\n",
    "\n",
    "    parts = op_str.where(mask).str.split('/', n=1, expand=True)\n",
    "    df.loc[mask & is_missing_str(df[ped_col]), ped_col] = parts[0]\n",
    "    df.loc[mask & is_missing_str(df[item_col]), item_col] = parts[1]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Se√ß√£o 2 ‚Äî Ordena√ß√£o Temporal & Diagn√≥sticos\n",
    "Aqui detectamos problemas como:\n",
    "- `BAD_ORDER`: quando `DT_FIM < DT_INICIO` na mesma linha.\n",
    "- `MONO_BREAK`: quebras de monotonicidade dentro da m√°quina.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_tempo_monotonico(df, col_maquina=\"CD_MAQUINA\"):\n",
    "    df = normalize_datetimes(df)\n",
    "    df[col_maquina] = df[col_maquina].astype(\"string\")\n",
    "\n",
    "    df[\"BAD_ORDER\"] = df[\"DT_FIM\"].notna() & df[\"DT_INICIO\"].notna() & (df[\"DT_FIM\"] < df[\"DT_INICIO\"])\n",
    "\n",
    "    df = df.sort_values([col_maquina, \"DT_INICIO\", \"DT_FIM\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    df[\"MONO_BREAK\"] = (\n",
    "        df.groupby(col_maquina)[\"DT_INICIO\"]\n",
    "          .apply(lambda s: s.diff().dt.total_seconds().fillna(0) < 0)\n",
    "          .reset_index(level=0, drop=True)\n",
    "          .astype(\"int8\")\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Se√ß√£o 3 ‚Äî Associar Paradas entre Ajustes (c√≥digo 1)\n",
    "Regra do cliente:\n",
    "> *Paradas entre dois Ajustes pertencem √† OP anterior.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associar_paradas_entre_ajustes(df,\n",
    "                                   col_maquina=\"CD_MAQUINA\",\n",
    "                                   col_evento=\"CD_PARADAOUCONV\",\n",
    "                                   col_op=\"CD_OP\",\n",
    "                                   ajuste_code=1):\n",
    "\n",
    "    df = df.copy()\n",
    "    df[col_maquina] = df[col_maquina].astype(\"string\")\n",
    "\n",
    "    op_atual = None\n",
    "    last_maq = None\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        maq = row[col_maquina]\n",
    "        cod = pd.to_numeric(row[col_evento], errors='coerce')\n",
    "        row_op = row[col_op]\n",
    "\n",
    "        if last_maq is None or maq != last_maq:\n",
    "            op_atual = None\n",
    "            last_maq = maq\n",
    "\n",
    "        if cod == ajuste_code and not is_missing_str(pd.Series([row_op])).iloc[0]:\n",
    "            op_atual = row_op\n",
    "            continue\n",
    "\n",
    "        if cod >= 1 and is_missing_str(pd.Series([row_op])).iloc[0]:\n",
    "            if op_atual is not None:\n",
    "                df.at[idx, col_op] = op_atual\n",
    "\n", 
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Se√ß√£o 4 ‚Äî Infer√™ncia de OP via Merge Temporal (ASOF)\n",
    "Regra do cliente:\n",
    "> *Paradas sem OP devem ser associadas √† pr√≥xima OP (pr√≥ximo DT_INICIO) dentro de uma toler√¢ncia de 30 min.*\n",
    "\n",
    "\n",
    "Aqui fazemos o merge **por m√°quina**, evitando erros de ordena√ß√£o (`left keys must be sorted`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_op_asof(df, tolerancia_min=30):\n",
    "    df = df.copy()\n",
    "    df = normalize_datetimes(df)\n",
    "    df[\"__IDX__\"] = np.arange(len(df))\n",
    "\n",
    "    cod = pd.to_numeric(df[\"CD_PARADAOUCONV\"], errors='coerce').fillna(0)\n",
    "    mask_parada = cod >= 1\n",
    "    mask_sem_op = is_missing_str(df[\"CD_OP\"])\n",
    "\n",
    "    left = df.loc[mask_parada & mask_sem_op & df[\"DT_FIM\"].notna(), [\"__IDX__\", \"CD_MAQUINA\", \"DT_FIM\"]]\n",
    "    left = left.rename(columns={\"DT_FIM\": \"KEY_TIME\"})\n",
    "\n",
    "    right = df.loc[(~mask_sem_op) & df[\"DT_INICIO\"].notna(), [\"CD_MAQUINA\", \"DT_INICIO\", \"CD_OP\"]]\n",
    "\n",
    "    updates = []\n",
    "    tol = pd.Timedelta(minutes=tolerancia_min)\n",
    "\n",
    "    for maq, l in left.groupby(\"CD_MAQUINA\"):\n",
    "        r = right[right[\"CD_MAQUINA\"] == maq]\n",
    "        if l.empty or r.empty:\n",
    "            continue\n",
    "\n",
    "        l = l.sort_values(\"KEY_TIME\")\n",
    "        r = r.sort_values(\"DT_INICIO\")\n",
    "\n",
    "        m = pd.merge_asof(\n",
    "            l,\n",
    "            r,\n",
    "            left_on=\"KEY_TIME\",\n",
    "            right_on=\"DT_INICIO\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=tol\n",
    "        )\n",
    "\n",
    "        ok = m[m[\"CD_OP\"].notna()]\n",
    "        for _, row in ok.iterrows():\n",
    "            updates.append((row[\"__IDX__\"], row[\"CD_OP\"]))\n",
    "\n",
    "    for idx, op in updates:\n",
    "        df.loc[df[\"__IDX__\"] == idx, \"CD_OP\"] = op\n",
    "\n",
    "    return df.drop(columns=[\"__IDX__\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Pipeline Final\n",
    "Executa todas as etapas na sequ√™ncia sugerida pelo cliente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_paradas_ops(df):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Ajustar datas\n",
    "    df = normalize_datetimes(df)\n",
    "\n",
    "    # 2) Split OP -> Pedido/Item\n",
    "    df = split_op_into_cols(df)\n",
    "\n",
    "    # 3) Ordena√ß√£o e diagn√≥sticos\n",
    "    df = preparar_tempo_monotonico(df)\n",
    "\n",
    "    # 4) Paradas entre ajustes\n",
    "    df = associar_paradas_entre_ajustes(df)\n",
    "\n",
    "    # 5) ASOF\n",
    "    df = inferir_op_asof(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Como executar o pipeline\n",
    "\n",
    "```python\n",
    "df_tratado = pipeline_paradas_ops(df_merge)\n",
    "```\n",
    "\n",
    "‚úÖ Seu dataframe final ter√° OP preenchida, pedido/item recuperados, e diagn√≥sticos temporais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
