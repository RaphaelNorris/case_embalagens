{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Projeto: Associação Temporal de Paradas e OPs\n",
    "\n",
    "Este notebook organiza o pipeline para:\n",
    "\n",
    "1. Padronizar chaves (preencher `CD_PEDIDO` e `CD_ITEM` a partir de `CD_OP`).\n",
    "2. Ordenar temporalmente os eventos por máquina, com diagnósticos de monotonicidade.\n",
    "3. Associar paradas entre ajustes consecutivos.\n",
    "4. Inferir OP faltante via merge temporal (`merge_asof`) com tolerância.\n",
    "5. Marcar eventos próximos às trocas de turno.\n",
    "6. Tratar produções sem **Ajuste** explícito quando o setup for idêntico (ferramental/cores).\n",
    "\n",
    "---\n",
    "## Citações do Cliente\n",
    "\n",
    "> \"Exatamente. Não existe uma associação direta entre evento de Parada e evento de Produção. O sistema basicamente conta chapas e registra eventos de parada.\"\n",
    "\n",
    "> \"Toda vez que um evento é classificado como Ajuste (cód. 1) o operador informa ao sistema qual será a próxima ordem e automaticamente o sistema encerra a ordem anterior; todas as paradas que estiverem dentro do período entre 2 eventos de Ajuste são automaticamente classificadas como pertencentes àquela OP anterior.\"\n",
    "\n",
    "> \"Acredito que sejam apontamentos indevidos, ou seja, eventos de paradas associados a ordens de produção onde o sistema não conseguiu associar relação, muito provavelmente porque foram classificados erroneamente. Verifique se estes eventos não estão com horários relacionados às trocas de turno (~ 05:00 ; 13:00 ; 21:00).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Índice (Table of Contents)\n",
    "\n",
    "1. Projeto / Citações do Cliente\n",
    "2. Índice\n",
    "3. Setup (imports, utilitários)\n",
    "4. Dados de Entrada\n",
    "5. Seleção e Transformação de Máquinas\n",
    "6. Merge Base\n",
    "7. Padronização de Chaves (OP → Pedido/Item)\n",
    "8. Escopo e Filtros (remover código 0)\n",
    "9. Preparação Temporal e Monotonicidade\n",
    "10. Associação entre Ajustes (Paradas → OP anterior)\n",
    "11. Inferência via Merge Temporal (asof)\n",
    "12. Marcação de Troca de Turno\n",
    "13. Diagnósticos Rápidos\n",
    "14. Pipeline Integrado\n",
    "15. Execução Final (opcional)\n",
    "16. Produções Sem Ajuste Explícito (setup idêntico)\n",
    "17. Auditorias e Sanity Checks\n",
    "18. Persistência (salvar parquet/csv)\n",
    "19. Amostras de Casos Suspeitos (perto de turno)\n",
    "20. Anexo: Utilitários de Depuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Setup (imports, utilitários)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Tokens que representam ausência/placeholder\n",
    "MISSING_TOKENS = {\"\", \"-1\", \"None\", \"nan\"}\n",
    "\n",
    "def is_missing_str(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    return s.isna() | s.str.strip().isin(MISSING_TOKENS)\n",
    "\n",
    "def to_datetime_safe(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def normalize_datetimes(df: pd.DataFrame, cini: str = \"DT_INICIO\", cfim: str = \"DT_FIM\") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[cini] = to_datetime_safe(out[cini])\n",
    "    out[cfim]  = to_datetime_safe(out[cfim])\n",
    "    return out\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dados de Entrada\n",
    "\n",
    "Carrega paradas, facas, máquinas e tarefas conforme caminhos do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paradas   = pd.read_parquet(\"../../../data/raw/tb_paradas.parquet\")\n",
    "df_facas     = pd.read_parquet(\"../../../data/raw/tb_facas.parquet\")\n",
    "df_maquinas  = pd.read_parquet(\"../../../data/raw/tb_maquina.parquet\")\n",
    "df_tarefcon  = pd.read_parquet(\"./../../../data/raw/tb_tarefcon.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seleção e Transformação de Máquinas\n",
    "\n",
    "- Filtra `CD_TIPO` em {1, 3}.\n",
    "- Mantém `ID_GRUPOMAQUINA` em {8, 18, 22, 23}.\n",
    "- Renomeia `QT_NRDECORES` para `QT_NRDECORES_MAQUINA`.\n",
    "- Mapeia `CD_TIPO` para texto descritivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maquinas_fil = df_maquinas[df_maquinas[\"CD_TIPO\"].astype(\"string\").isin([\"1\", \"3\"])].copy()\n",
    "df_maquinas_fil = df_maquinas_fil[df_maquinas_fil[\"ID_GRUPOMAQUINA\"].astype(\"string\").isin([\"8\", \"18\", \"22\", \"23\"])].copy()\n",
    "df_maquinas_fil = df_maquinas_fil.rename(columns={\"QT_NRDECORES\": \"QT_NRDECORES_MAQUINA\"})\n",
    "\n",
    "status_descr = {1: \"C/V\", 3: \"Flexo\"}\n",
    "df_maquinas_fil[\"TX_TIPO_MAQUINA\"] = (\n",
    "    df_maquinas_fil[\"CD_TIPO\"].astype(int).map(status_descr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge Base\n",
    "\n",
    "- `df_tarefcon` × `df_maquinas_fil` por `CD_MAQUINA` (inner)\n",
    "- Enriquecimento com `df_paradas` pelo código `CD_PARADAOUCONV` → `df_paradas.CD_PARADA` (left)\n",
    "- Reorganização de colunas e normalização de datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_tarefcon.merge(\n",
    "    df_maquinas_fil[[\"CD_MAQUINA\", \"QT_NRDECORES_MAQUINA\", \"ID_GRUPOMAQUINA\", \"TX_TIPO_MAQUINA\"]],\n",
    "    on=\"CD_MAQUINA\",\n",
    "    how=\"inner\",\n",
    ").merge(\n",
    "    df_paradas[[\"CD_PARADA\", \"TX_DESCRICAO\", \"FL_EXTERNA\", \"FL_USADACONVERSAO\"]],\n",
    "    left_on=\"CD_PARADAOUCONV\",\n",
    "    right_on=\"CD_PARADA\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_merge = df_merge[sorted(df_merge.columns)].copy()\n",
    "df_merge = normalize_datetimes(df_merge, cini=\"DT_INICIO\", cfim=\"DT_FIM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Padronização de Chaves (OP → Pedido/Item)\n",
    "\n",
    "Em 96% dos registros que apresentam parada, não há valores para `ID_ITEM` e `ID_PEDIDO`. Como `CD_OP` é `PEDIDO/ITEM`, recuperamos ambos **apenas onde estiver faltando**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preencher_pedido_item_de_op(\n",
    "    df: pd.DataFrame,\n",
    "    op_col: str = \"CD_OP\",\n",
    "    pedido_col: str = \"CD_PEDIDO\",\n",
    "    item_col: str = \"CD_ITEM\",\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if pedido_col not in out.columns:\n",
    "        out[pedido_col] = pd.NA\n",
    "    if item_col not in out.columns:\n",
    "        out[item_col] = pd.NA\n",
    "\n",
    "    op_str = out.get(op_col, pd.Series(pd.NA, index=out.index)).astype(\"string\").str.strip()\n",
    "    op_valida = (~is_missing_str(op_str)) & op_str.str.contains(\"/\", regex=False)\n",
    "    partes = op_str.where(op_valida).str.split(\"/\", n=1, expand=True)\n",
    "    if isinstance(partes, pd.DataFrame) and partes.shape[1] == 2:\n",
    "        ped_from_op  = partes[0].astype(\"string\").str.strip()\n",
    "        item_from_op = partes[1].astype(\"string\").str.strip()\n",
    "        mask_ped_missing  = is_missing_str(out[pedido_col].astype(\"string\"))\n",
    "        mask_item_missing = is_missing_str(out[item_col].astype(\"string\"))\n",
    "        out.loc[op_valida & mask_ped_missing, pedido_col]  = ped_from_op[op_valida & mask_ped_missing]\n",
    "        out.loc[op_valida & mask_item_missing, item_col]   = item_from_op[op_valida & mask_item_missing]\n",
    "    return out\n",
    "\n",
    "# Aplica o preenchimento de chaves\n",
    "df_merge = preencher_pedido_item_de_op(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Escopo e Filtros (remover código 0)\n",
    "\n",
    "Remove eventos com `CD_PARADAOUCONV == 0` (ex.: esteiras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_zero = pd.to_numeric(df_merge[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0) == 0\n",
    "df_merge = df_merge[~mask_zero].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Preparação Temporal e Monotonicidade\n",
    "\n",
    "Cria diagnósticos:\n",
    "- `BAD_ORDER`: `DT_FIM < DT_INICIO`\n",
    "- `MONO_BREAK`: quebras de monotonicidade de `DT_INICIO` por máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_tempo_monotonico(\n",
    "    df: pd.DataFrame,\n",
    "    col_maquina: str = \"CD_MAQUINA\",\n",
    "    col_inicio: str = \"DT_INICIO\",\n",
    "    col_fim: str = \"DT_FIM\",\n",
    "    corrigir_fim_menor_inicio: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    out = normalize_datetimes(df, cini=col_inicio, cfim=col_fim)\n",
    "    out[col_maquina] = out[col_maquina].astype(\"string\")\n",
    "\n",
    "    out = out[~(out[col_inicio].isna() & out[col_fim].isna())].copy()\n",
    "\n",
    "    out[\"BAD_ORDER\"] = (\n",
    "        out[col_fim].notna() & out[col_inicio].notna() & (out[col_fim] < out[col_inicio])\n",
    "    )\n",
    "\n",
    "    out = out.sort_values([col_maquina, col_inicio, col_fim], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    out[\"MONO_BREAK\"] = (\n",
    "        out.groupby(col_maquina, sort=False)[col_inicio]\n",
    "        .apply(lambda s: s.diff().dt.total_seconds().fillna(0) < 0)\n",
    "        .reset_index(level=0, drop=True)\n",
    "        .astype(\"int8\")\n",
    "    )\n",
    "\n",
    "    if corrigir_fim_menor_inicio:\n",
    "        mask_fix = out[\"BAD_ORDER\"]\n",
    "        out.loc[mask_fix, col_fim] = out.loc[mask_fix, col_inicio]\n",
    "        out[\"BAD_ORDER\"] = (\n",
    "            out[col_fim].notna() & out[col_inicio].notna() & (out[col_fim] < out[col_inicio])\n",
    "        )\n",
    "    return out\n",
    "\n",
    "# Aplica ordenação e diagnósticos\n",
    "df_merge = preparar_tempo_monotonico(df_merge, corrigir_fim_menor_inicio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Associação entre Ajustes (Paradas → OP anterior)\n",
    "\n",
    "Regra: paradas entre dois ajustes pertencem à **OP anterior**. O ajuste é `CD_PARADAOUCONV == 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associar_paradas_entre_ajustes(\n",
    "    df: pd.DataFrame,\n",
    "    col_maquina: str = \"CD_MAQUINA\",\n",
    "    col_evento: str = \"CD_PARADAOUCONV\",\n",
    "    col_op: str = \"CD_OP\",\n",
    "    ajuste_code: int = 1,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[col_maquina] = out[col_maquina].astype(\"string\")\n",
    "\n",
    "    op_atual_por_maq = {}\n",
    "    for idx, row in out.iterrows():\n",
    "        maq = row[col_maquina]\n",
    "        cod = pd.to_numeric(row[col_evento], errors=\"coerce\")\n",
    "        row_op = row[col_op]\n",
    "\n",
    "        # Ajuste define a nova OP\n",
    "        if cod == ajuste_code and not is_missing_str(pd.Series([row_op])).iloc[0]:\n",
    "            op_atual_por_maq[maq] = row_op\n",
    "            continue\n",
    "\n",
    "        # Parada (>=1) sem OP herda a OP atual da máquina\n",
    "        if (cod >= 1) and is_missing_str(pd.Series([row_op])).iloc[0]:\n",
    "            if maq in op_atual_por_maq:\n",
    "                out.at[idx, col_op] = op_atual_por_maq[maq]\n",
    "\n",
    "    return out\n",
    "\n",
    "# Aplica associação entre ajustes\n",
    "df_merge = df_merge.sort_values([\"CD_MAQUINA\", \"DT_INICIO\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "df_merge = associar_paradas_entre_ajustes(df_merge)\n",
    "df_merge = preencher_pedido_item_de_op(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Inferência via Merge Temporal (asof)\n",
    "\n",
    "Regra: paradas sem `CD_OP` → casar `DT_FIM` da parada com próximo `DT_INICIO` com `CD_OP` **na mesma máquina** dentro de tolerância (ex.: 30 min).\n",
    "\n",
    "Para evitar `ValueError: left keys must be sorted`, o merge é feito **por máquina**, ordenando as chaves em cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_op_asof(df: pd.DataFrame, tolerancia_min: int = 30) -> pd.DataFrame:\n",
    "    out = normalize_datetimes(df)\n",
    "    out[\"__IDX__\"] = np.arange(len(out))\n",
    "\n",
    "    cod = pd.to_numeric(out[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0)\n",
    "    mask_parada = cod >= 1\n",
    "    mask_sem_op = is_missing_str(out[\"CD_OP\"])\n",
    "\n",
    "    left_all  = out.loc[mask_parada & mask_sem_op & out[\"DT_FIM\"].notna(), [\"__IDX__\", \"CD_MAQUINA\", \"DT_FIM\"]].copy()\n",
    "    left_all  = left_all.rename(columns={\"DT_FIM\": \"KEY_TIME\"})\n",
    "    right_all = out.loc[(~mask_sem_op) & out[\"DT_INICIO\"].notna(), [\"CD_MAQUINA\", \"DT_INICIO\", \"CD_OP\"]].copy()\n",
    "\n",
    "    # tipagem consistente\n",
    "    left_all[\"CD_MAQUINA\"]  = left_all[\"CD_MAQUINA\"].astype(\"string\")\n",
    "    right_all[\"CD_MAQUINA\"] = right_all[\"CD_MAQUINA\"].astype(\"string\")\n",
    "\n",
    "    updates = []\n",
    "    tol = pd.Timedelta(minutes=tolerancia_min)\n",
    "\n",
    "    for maq, left in left_all.groupby(\"CD_MAQUINA\", sort=False):\n",
    "        right = right_all[right_all[\"CD_MAQUINA\"] == maq]\n",
    "        if left.empty or right.empty:\n",
    "            continue\n",
    "\n",
    "        left  = left.sort_values([\"KEY_TIME\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "        right = right.sort_values([\"DT_INICIO\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "        matched = pd.merge_asof(\n",
    "            left,\n",
    "            right,\n",
    "            left_on=\"KEY_TIME\",\n",
    "            right_on=\"DT_INICIO\",\n",
    "            direction=\"forward\",\n",
    "            tolerance=tol\n",
    "        )\n",
    "\n",
    "        ok = matched[matched[\"CD_OP\"].notna()]\n",
    "        if not ok.empty:\n",
    "            updates.extend(ok[[\"__IDX__\", \"CD_OP\"]].itertuples(index=False, name=None))\n",
    "\n",
    "    for idx, op in updates:\n",
    "        out.loc[out[\"__IDX__\"] == idx, \"CD_OP\"] = op\n",
    "\n",
    "    out = out.drop(columns=[\"__IDX__\"])\n",
    "    out = preencher_pedido_item_de_op(out)\n",
    "    return out\n",
    "\n",
    "# Aplica merge temporal\n",
    "df_merge = inferir_op_asof(df_merge, tolerancia_min=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Marcação de Troca de Turno (05:00, 13:00, 21:00)\n",
    "\n",
    "Citação do cliente: verificar eventos próximos às trocas de turno. Cria colunas:\n",
    "- `NEAR_SHIFT_INICIO`\n",
    "- `NEAR_SHIFT_FIM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marcar_troca_turno(df: pd.DataFrame, janela_min: int = 30) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"DT_INICIO\"] = to_datetime_safe(out[\"DT_INICIO\"])\n",
    "    out[\"DT_FIM\"]    = to_datetime_safe(out[\"DT_FIM\"])\n",
    "\n",
    "    def near_shift(series: pd.Series) -> pd.Series:\n",
    "        series = to_datetime_safe(series)\n",
    "        mins = series.dt.hour * 60 + series.dt.minute\n",
    "        anchors = [5*60, 13*60, 21*60]\n",
    "        deltas = [\n",
    "            (mins - a).abs().where((mins - a).abs() <= 720, 1440 - (mins - a).abs())\n",
    "            for a in anchors\n",
    "        ]\n",
    "        dmin = pd.concat(deltas, axis=1).min(axis=1)\n",
    "        return (dmin <= janela_min).astype(\"int8\")\n",
    "\n",
    "    out[\"NEAR_SHIFT_INICIO\"] = near_shift(out[\"DT_INICIO\"])\n",
    "    out[\"NEAR_SHIFT_FIM\"]    = near_shift(out[\"DT_FIM\"])\n",
    "    return out\n",
    "\n",
    "# Marca trocas de turno\n",
    "df_merge = marcar_troca_turno(df_merge, janela_min=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Diagnósticos Rápidos\n",
    "\n",
    "- Amostra de paradas (>=1) mostrando OP e proximidade de turno.\n",
    "- Estatísticas básicas de flags temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra_paradas = df_merge[pd.to_numeric(df_merge[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0) >= 1][\n",
    "    [\"CD_MAQUINA\", \"DT_INICIO\", \"DT_FIM\", \"CD_PARADAOUCONV\", \"CD_OP\", \"CD_PEDIDO\", \"CD_ITEM\", \"NEAR_SHIFT_INICIO\", \"NEAR_SHIFT_FIM\"]\n",
    "].sample(20, random_state=42) if df_merge.shape[0] >= 20 else df_merge\n",
    "\n",
    "stats_flags = {\n",
    "    \"total_linhas\": int(df_merge.shape[0]),\n",
    "    \"bad_order\": int(df_merge.get(\"BAD_ORDER\", pd.Series([False]*len(df_merge))).sum()),\n",
    "    \"mono_break\": int(df_merge.get(\"MONO_BREAK\", pd.Series([0]*len(df_merge))).sum()),\n",
    "    \"near_shift_inicio\": int(df_merge.get(\"NEAR_SHIFT_INICIO\", pd.Series([0]*len(df_merge))).sum()),\n",
    "    \"near_shift_fim\": int(df_merge.get(\"NEAR_SHIFT_FIM\", pd.Series([0]*len(df_merge))).sum()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Pipeline Integrado\n",
    "\n",
    "Executa todas as etapas na ordem recomendada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_paradas_ops(df: pd.DataFrame, tolerancia_min: int = 30, janela_turno_min: int = 30) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out = normalize_datetimes(out)\n",
    "\n",
    "    # 1) OP → Pedido/Item (precoce, só preenche vazios)\n",
    "    out = preencher_pedido_item_de_op(out)\n",
    "\n",
    "    # 2) Remove CD_PARADAOUCONV == 0\n",
    "    mask_zero_local = pd.to_numeric(out[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0) == 0\n",
    "    out = out[~mask_zero_local].copy()\n",
    "\n",
    "    # 3) Ordenação + diagnósticos\n",
    "    out = preparar_tempo_monotonico(out, corrigir_fim_menor_inicio=False)\n",
    "\n",
    "    # 4) Paradas entre ajustes\n",
    "    out = out.sort_values([\"CD_MAQUINA\", \"DT_INICIO\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "    out = associar_paradas_entre_ajustes(out)\n",
    "    out = preencher_pedido_item_de_op(out)\n",
    "\n",
    "    # 5) Merge temporal (asof) por máquina\n",
    "    out = inferir_op_asof(out, tolerancia_min=tolerancia_min)\n",
    "\n",
    "    # 6) Marca proximidade de troca de turno\n",
    "    out = marcar_troca_turno(out, janela_min=janela_turno_min)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Execução Final (opcional)\n",
    "\n",
    "Descomente para executar tudo de ponta a ponta, caso ainda não tenha rodado as etapas acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge = pipeline_paradas_ops(df_merge, tolerancia_min=30, janela_turno_min=30)\n",
    "# df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Produções Sem Ajuste Explícito (setup idêntico)\n",
    "\n",
    "Quando duas OPs consecutivas **não** possuem um Ajuste explícito (cód. 1) entre elas, **mas** o setup é idêntico, não devemos penalizar a ausência de ajuste.\n",
    "\n",
    "**Critério de setup idêntico (ajustável):**\n",
    "- Mesmo `CD_FACA` **e**\n",
    "- Mesma `QT_NRDECORES_MAQUINA` (ou coluna equivalente de cores)\n",
    "\n",
    "Resultado:\n",
    "- Cria `SETUP_SAME` por linha (comparando com linha anterior da mesma máquina)\n",
    "- Cria `AUSENCIA_AJUSTE_PERMITIDA` quando há troca de OP sem evento 1 entre os blocos, mas `SETUP_SAME == 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marcar_setup_identico(\n",
    "    df: pd.DataFrame,\n",
    "    col_maquina: str = \"CD_MAQUINA\",\n",
    "    col_op: str = \"CD_OP\",\n",
    "    col_faca: str = \"CD_FACA\",\n",
    "    col_cores: str = \"QT_NRDECORES_MAQUINA\",\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[[col_faca, col_cores, col_maquina, col_op]] = out[[col_faca, col_cores, col_maquina, col_op]].astype(\"string\")\n",
    "    out = out.sort_values([col_maquina, \"DT_INICIO\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "    same_faca  = out.groupby(col_maquina)[col_faca].apply(lambda s: s == s.shift(1)).reset_index(level=0, drop=True)\n",
    "    same_cores = out.groupby(col_maquina)[col_cores].apply(lambda s: s == s.shift(1)).reset_index(level=0, drop=True)\n",
    "    out[\"SETUP_SAME\"] = (same_faca & same_cores).astype(\"int8\")\n",
    "    return out\n",
    "\n",
    "def permitir_ausencia_ajuste_sem_penalizar(\n",
    "    df: pd.DataFrame,\n",
    "    col_maquina: str = \"CD_MAQUINA\",\n",
    "    col_evento: str = \"CD_PARADAOUCONV\",\n",
    "    col_op: str = \"CD_OP\",\n",
    "    ajuste_code: int = 1,\n",
    ") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[[col_maquina, col_op]] = out[[col_maquina, col_op]].astype(\"string\")\n",
    "    out = out.sort_values([col_maquina, \"DT_INICIO\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # Marca se há um Ajuste explícito nesta linha\n",
    "    cod = pd.to_numeric(out[col_evento], errors=\"coerce\").fillna(0)\n",
    "    out[\"IS_AJUSTE\"] = (cod == ajuste_code).astype(\"int8\")\n",
    "\n",
    "    # Transições de OP por máquina\n",
    "    prev_op = out.groupby(col_maquina)[col_op].shift(1)\n",
    "    out[\"OP_CHANGED\"] = (out[col_op] != prev_op).astype(\"int8\")\n",
    "\n",
    "    # Houve algum ajuste entre a OP anterior e esta?\n",
    "    # Para cada máquina, olhamos se entre um índice de mudança e o anterior ocorreu IS_AJUSTE==1\n",
    "    out[\"AUSENCIA_AJUSTE_PERMITIDA\"] = 0\n",
    "    for maq, g in out.groupby(col_maquina, sort=False):\n",
    "        idxs = g.index.tolist()\n",
    "        for i in range(1, len(idxs)):\n",
    "            cur_idx = idxs[i]\n",
    "            prev_idx = idxs[i-1]\n",
    "            # Se trocou OP nesta linha\n",
    "            if out.at[cur_idx, \"OP_CHANGED\"] == 1:\n",
    "                # Verifica existência de ajuste explícito entre prev_idx (exclusivo) e cur_idx (exclusivo)\n",
    "                janela = out.loc[prev_idx+1:cur_idx-1]\n",
    "                houve_ajuste = int(janela[\"IS_AJUSTE\"].sum()) > 0 if not janela.empty else False\n",
    "                # Se não houve ajuste, mas setup idêntico, então permitimos ausência\n",
    "                if not houve_ajuste and out.at[cur_idx, \"SETUP_SAME\"] == 1:\n",
    "                    out.at[cur_idx, \"AUSENCIA_AJUSTE_PERMITIDA\"] = 1\n",
    "    return out\n",
    "\n",
    "# Aplica marcações\n",
    "df_merge = marcar_setup_identico(df_merge, col_faca=\"CD_FACA\", col_cores=\"QT_NRDECORES_MAQUINA\")\n",
    "df_merge = permitir_ausencia_ajuste_sem_penalizar(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Auditorias e Sanity Checks\n",
    "\n",
    "Funções utilitárias para checar condições típicas de erro ou inconsistência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_asof_sort(df: pd.DataFrame) -> dict:\n",
    "    report = {\"left_sorted\": True, \"right_sorted\": True, \"by_group\": []}\n",
    "    tmp = normalize_datetimes(df)\n",
    "    cod = pd.to_numeric(tmp[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0)\n",
    "    mask_parada = cod >= 1\n",
    "    mask_sem_op = is_missing_str(tmp[\"CD_OP\"])    \n",
    "    left = tmp.loc[mask_parada & mask_sem_op & tmp[\"DT_FIM\"].notna(), [\"CD_MAQUINA\", \"DT_FIM\"]].copy()\n",
    "    left.rename(columns={\"DT_FIM\": \"KEY_TIME\"}, inplace=True)\n",
    "    right = tmp.loc[(~mask_sem_op) & tmp[\"DT_INICIO\"].notna(), [\"CD_MAQUINA\", \"DT_INICIO\", \"CD_OP\"]].copy()\n",
    "    left[\"CD_MAQUINA\"] = left[\"CD_MAQUINA\"].astype(\"string\")\n",
    "    right[\"CD_MAQUINA\"] = right[\"CD_MAQUINA\"].astype(\"string\")\n",
    "\n",
    "    for maq, gleft in left.groupby(\"CD_MAQUINA\", sort=False):\n",
    "        gright = right[right[\"CD_MAQUINA\"] == maq]\n",
    "        ok_left  = gleft.sort_values([\"KEY_TIME\"], kind=\"mergesort\").index.equals(gleft.sort_index().sort_values().index)\n",
    "        ok_right = gright.sort_values([\"DT_INICIO\"], kind=\"mergesort\").index.equals(gright.sort_index().sort_values().index)\n",
    "        report[\"by_group\"].append({\"CD_MAQUINA\": str(maq), \"left_keys_sorted\": bool(ok_left), \"right_keys_sorted\": bool(ok_right)})\n",
    "        report[\"left_sorted\"]  &= ok_left\n",
    "        report[\"right_sorted\"] &= ok_right\n",
    "    return report\n",
    "\n",
    "def audit_missing_ops(df: pd.DataFrame) -> dict:\n",
    "    s = df[\"CD_OP\"].astype(\"string\")\n",
    "    return {\n",
    "        \"total\": int(df.shape[0]),\n",
    "        \"faltando_op\": int(is_missing_str(s).sum())\n",
    "    }\n",
    "\n",
    "# Exemplo de uso (opcional):\n",
    "# asof_sort_report = audit_asof_sort(df_merge)\n",
    "# missing_ops_report = audit_missing_ops(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Persistência (salvar parquet/csv)\n",
    "\n",
    "Salva resultado final processado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../../../data/processed\"\n",
    "ensure_dir(OUTPUT_DIR)\n",
    "out_parquet = os.path.join(OUTPUT_DIR, \"df_paradas_ops.parquet\")\n",
    "out_csv     = os.path.join(OUTPUT_DIR, \"df_paradas_ops.csv\")\n",
    "\n",
    "# Descomente para salvar\n",
    "# df_merge.to_parquet(out_parquet, index=False)\n",
    "# df_merge.to_csv(out_csv, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Amostras de Casos Suspeitos (perto de turno)\n",
    "\n",
    "Exibe linhas de paradas sem OP original que foram inferidas e ocorrem **perto de trocas de turno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amostras_perto_de_turno(df: pd.DataFrame, n: int = 20) -> pd.DataFrame:\n",
    "    # Paradas (>=1) com OP válida agora e perto de turno\n",
    "    cod = pd.to_numeric(df[\"CD_PARADAOUCONV\"], errors=\"coerce\").fillna(0)\n",
    "    mask_parada = cod >= 1\n",
    "    mask_op_val = ~is_missing_str(df[\"CD_OP\"]) & df[\"CD_OP\"].astype(\"string\").str.contains(\"/\")\n",
    "    mask_turno  = (df[\"NEAR_SHIFT_INICIO\"] == 1) | (df[\"NEAR_SHIFT_FIM\"] == 1)\n",
    "    sample = df.loc[mask_parada & mask_op_val & mask_turno, [\n",
    "        \"CD_MAQUINA\", \"DT_INICIO\", \"DT_FIM\", \"CD_PARADAOUCONV\", \"CD_OP\", \"CD_PEDIDO\", \"CD_ITEM\",\n",
    "        \"NEAR_SHIFT_INICIO\", \"NEAR_SHIFT_FIM\"\n",
    "    ]]\n",
    "    if sample.shape[0] > n:\n",
    "        return sample.sample(n, random_state=42)\n",
    "    return sample\n",
    "\n",
    "# exemplos (opcional):\n",
    "# amostras_turno = amostras_perto_de_turno(df_merge, n=20)\n",
    "# amostras_turno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Anexo: Utilitários de Depuração\n",
    "\n",
    "Funções auxiliares para inspeção rápida de encadeamentos em uma máquina específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trilha_maquina(df: pd.DataFrame, maquina: str, n: int = 50) -> pd.DataFrame:\n",
    "    g = df[df[\"CD_MAQUINA\"].astype(\"string\") == str(maquina)].copy()\n",
    "    g = g.sort_values([\"DT_INICIO\", \"DT_FIM\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "    cols = [\n",
    "        \"CD_MAQUINA\", \"DT_INICIO\", \"DT_FIM\", \"CD_PARADAOUCONV\", \"IS_AJUSTE\", \"SETUP_SAME\",\n",
    "        \"AUSENCIA_AJUSTE_PERMITIDA\", \"CD_OP\", \"CD_PEDIDO\", \"CD_ITEM\",\n",
    "        \"NEAR_SHIFT_INICIO\", \"NEAR_SHIFT_FIM\", \"BAD_ORDER\", \"MONO_BREAK\"\n",
    "    ]\n",
    "    cols = [c for c in cols if c in g.columns]\n",
    "    if g.shape[0] > n:\n",
    "        return g[cols].head(n)\n",
    "    return g[cols]\n",
    "\n",
    "# exemplo (opcional):\n",
    "# trilha_maquina(df_merge, maquina=\"DRO3\", n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
