{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Processamento e Sumarização da Tabela de Pedidos\n",
    "\n",
    "## Objetivo\n",
    "Processar a tabela `tb_pedidos` mantendo specs históricas (no momento do pedido) para merge com TAREFCON.\n",
    "\n",
    "## Diferenças vs ITENS\n",
    "- **ITENS**: 1 linha por item (specs atuais)\n",
    "- **PEDIDOS**: N linhas por item (histórico de pedidos com specs no momento)\n",
    "- **Uso**: PEDIDOS é preferencial para merge (specs históricas)\n",
    "\n",
    "## Estratégia\n",
    "1. Filtrar pedidos relevantes (presentes na base de produção)\n",
    "2. Remover pedidos cancelados/suspensos\n",
    "3. Padronizar nomenclatura (match com ITENS)\n",
    "4. Criar features derivadas (compatíveis com ITENS + específicas de pedido)\n",
    "5. Validar e exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros em tb_pedidos: 406,890\n",
      "Colunas em tb_pedidos: 87\n",
      "Itens únicos na base de produção: 9,647\n",
      "Pedidos únicos na base de produção: 230,174\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados\n",
    "df_pedidos = pd.read_parquet(\"../../../data/raw/tb_pedidos.parquet\")\n",
    "df_merge_base = pd.read_parquet(\"df_final_base.parquet\")\n",
    "\n",
    "# Listas de itens e pedidos relevantes (presentes na produção)\n",
    "list_itens = list(df_merge_base.CD_ITEM.unique())\n",
    "list_pedidos = list(df_merge_base.CD_PEDIDO.unique())\n",
    "\n",
    "print(f\"Registros em tb_pedidos: {df_pedidos.shape[0]:,}\")\n",
    "print(f\"Colunas em tb_pedidos: {df_pedidos.shape[1]}\")\n",
    "print(f\"Itens únicos na base de produção: {len(list_itens):,}\")\n",
    "print(f\"Pedidos únicos na base de produção: {len(list_pedidos):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter-header",
   "metadata": {},
   "source": [
    "## 2. Filtragem de Pedidos Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "filter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após filtro por itens/pedidos produzidos: 230,603\n",
      "Redução: 43.3%\n",
      "Após remover cancelados/suspensos: 230,543\n",
      "Pedidos únicos: 230,076\n",
      "Itens únicos: 7,623\n"
     ]
    }
   ],
   "source": [
    "# Filtrar por itens e pedidos que existem na produção\n",
    "df_pedidos_fil = df_pedidos[\n",
    "    df_pedidos.CD_ITEM.isin(list_itens) & \n",
    "    df_pedidos.CD_PEDIDO.isin(list_pedidos)\n",
    "].copy()\n",
    "\n",
    "print(f\"Após filtro por itens/pedidos produzidos: {df_pedidos_fil.shape[0]:,}\")\n",
    "print(f\"Redução: {(1 - df_pedidos_fil.shape[0]/df_pedidos.shape[0])*100:.1f}%\")\n",
    "\n",
    "# Remover pedidos cancelados e suspensos\n",
    "df_pedidos_fil = df_pedidos_fil[\n",
    "    (df_pedidos_fil[\"ST_PEDIDO\"] != \"4\") &  # Cancelados\n",
    "    (df_pedidos_fil[\"FL_SUSPENSO\"] == \"0\") &  # Suspensos\n",
    "    (df_pedidos_fil[\"FL_SUSPOUCANCEL\"] == \"0\")  # Suspensos ou cancelados\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"Após remover cancelados/suspensos: {df_pedidos_fil.shape[0]:,}\")\n",
    "print(f\"Pedidos únicos: {df_pedidos_fil.CD_PEDIDO.nunique():,}\")\n",
    "print(f\"Itens únicos: {df_pedidos_fil.CD_ITEM.nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cols-header",
   "metadata": {},
   "source": [
    "## 3. Remoção de Colunas Irrelevantes\n",
    "\n",
    "Remover colunas de:\n",
    "- **Paletização**: logística pós-produção\n",
    "- **Status processados**: já filtrados\n",
    "- **Datas**: não relevantes para specs do produto\n",
    "- **Referências**: redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "drop-cols",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas removidas: 29\n",
      "Colunas restantes: 58\n"
     ]
    }
   ],
   "source": [
    "# Colunas a remover\n",
    "cols_drop = [\n",
    "    # Paletização (logística, não afeta produção)\n",
    "    \"CD_PALETE\", \"FL_PALETIZADO\", \"FL_AMARRADO\",\n",
    "    \"QT_PECASPORPACOTE\", \"QT_PECASPORPALETE\", \n",
    "    \"QT_UNIDADESPORPALETE\", \"QT_PACOTESPORPALETE\",\n",
    "    \"VL_ALTURAPACOTE\", \"VL_ALTURAPALETEFECHADO\",\n",
    "    \"VL_COMPPALETEFECHADO\", \"VL_COMPPACOTE\",\n",
    "    \"VL_LARGPACOTE\", \"VL_LARGPALETEFECHADO\",\n",
    "    \"VL_PACOTESCOMPRIMENTO\", \"VL_PACOTESLARGURA\", \"VL_PACOTESALTURA\",\n",
    "    \"VL_VOLUMEPACOTEFECHADOM3\", \"VL_VOLUMEPALETEFECHADOM3\", \n",
    "    \"VL_VOLUMEFECHADOPEDIDO\",\n",
    "    \n",
    "    # Status (já processados nos filtros)\n",
    "    \"ST_PEDIDO\", \"FL_SUSPENSO\", \"FL_SUSPOUCANCEL\",\n",
    "    \"TX_DESCRSTATUSPEDIDO\",\n",
    "    \n",
    "    # Datas e tipo (remover por enquanto - pode adicionar depois se necessário)\n",
    "    \"DT_ENTREGA2\", \"DT_ENTREGAORIGINAL\",\n",
    "    \"TX_DESCRTIPODOPEDIDO\", \"TX_DESCTIPOENTREGA\", \"FL_TIPOENTREGA\",\n",
    "    \n",
    "    # Referências e metadados\n",
    "    \"CD_REFERENCIA\",\n",
    "]\n",
    "\n",
    "# Verificar quais existem\n",
    "cols_existentes = [col for col in cols_drop if col in df_pedidos_fil.columns]\n",
    "df_pedidos_fil = df_pedidos_fil.drop(columns=cols_existentes)\n",
    "\n",
    "print(f\"Colunas removidas: {len(cols_existentes)}\")\n",
    "print(f\"Colunas restantes: {df_pedidos_fil.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rename-header",
   "metadata": {},
   "source": [
    "## 4. Padronização de Nomenclatura\n",
    "\n",
    "Renomear colunas para match com `nb_itens_processing.ipynb`:\n",
    "- **FL_** = Flags binários\n",
    "- **VL_** = Valores numéricos\n",
    "- **QT_** = Quantidades\n",
    "- **TX_** / **CAT_** = Categóricos\n",
    "- **CD_** = Códigos identificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas renomeadas: 12\n",
      "\n",
      "Primeiras 15 colunas:\n",
      "['CAT_COMPOSICAO', 'CAT_ESPELHO', 'CAT_FILME', 'CD_FACA', 'CD_ITEM', 'CD_PEDIDO', 'FL_CHAPA', 'FL_CONTROLE_ESPECIAL_IMPRESSAO', 'FL_LAP_INTERNO', 'FL_LAP_NO_COMPR', 'FL_PROLONG_LAP', 'FL_REFILADO', 'FL_RESINAINTERNA', 'FL_TESTE_EXIGELAUDO', 'ID_CLIENTE']\n"
     ]
    }
   ],
   "source": [
    "# Mapa de renomeação (match com ITENS)\n",
    "rename_map = {\n",
    "    # Testes de qualidade\n",
    "    \"FL_EXIGELAUDO\": \"FL_TESTE_EXIGELAUDO\",\n",
    "    \"VL_GRAMATURA\": \"VL_TESTE_GRAMATURA\",\n",
    "    \"QT_COBBINTMAXIMO\": \"VL_TESTE_COBB_INT_MAX\",\n",
    "    \"VL_COLUNAMINIMO\": \"VL_TESTE_COLUNA_MINIMO\",\n",
    "    \"VL_COMPRESSAO\": \"VL_TESTE_COMPRESSAO\",\n",
    "    \n",
    "    # Flags e controles\n",
    "    \"CD_TIPOFT2\": \"FL_CONTROLE_ESPECIAL_IMPRESSAO\",\n",
    "    \n",
    "    # LAP (serão convertidos para binário)\n",
    "    \"VL_LAPINTERNO\": \"FL_LAP_INTERNO\",\n",
    "    \"VL_LAPNOCOMP\": \"FL_LAP_NO_COMPR\",\n",
    "    \"QT_PROLONGLAP\": \"FL_PROLONG_LAP\",\n",
    "    \n",
    "    # Categóricos\n",
    "    \"TX_COMPOSICAO\": \"CAT_COMPOSICAO\",\n",
    "    \"CD_ESPELHO\": \"CAT_ESPELHO\",\n",
    "    \"CD_FILME\": \"CAT_FILME\",\n",
    "}\n",
    "\n",
    "df_pedidos_fil = df_pedidos_fil.rename(columns=rename_map)\n",
    "\n",
    "print(f\"Colunas renomeadas: {len(rename_map)}\")\n",
    "print(\"\\nPrimeiras 15 colunas:\")\n",
    "print(list(sorted(df_pedidos_fil.columns))[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standardize-header",
   "metadata": {},
   "source": [
    "## 5. Padronização de Valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standardize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_LAP_INTERNO: valores únicos = [np.float64(0.0), np.float64(1.0)]\n",
      "FL_LAP_NO_COMPR: valores únicos = [np.float64(0.0), np.float64(1.0)]\n",
      "FL_PROLONG_LAP: {0: 207770, 1: 22773}\n",
      "FL_CONTROLE_ESPECIAL_IMPRESSAO: {'0': 230307, '1': 236}\n",
      "\n",
      "✅ Padronização de valores concluída\n"
     ]
    }
   ],
   "source": [
    "# 1. Converter LAP flags: -1 → 0 (padronizar como binário)\n",
    "colunas_lap = [\"FL_LAP_INTERNO\", \"FL_LAP_NO_COMPR\"]\n",
    "for col in colunas_lap:\n",
    "    if col in df_pedidos_fil.columns:\n",
    "        df_pedidos_fil[col] = df_pedidos_fil[col].replace(-1, 0)\n",
    "        print(f\"{col}: valores únicos = {sorted(df_pedidos_fil[col].unique())}\")\n",
    "\n",
    "# 2. Converter FL_PROLONG_LAP para binário\n",
    "if \"FL_PROLONG_LAP\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"FL_PROLONG_LAP\"] = (df_pedidos_fil[\"FL_PROLONG_LAP\"] > 0).astype(int)\n",
    "    print(f\"FL_PROLONG_LAP: {df_pedidos_fil['FL_PROLONG_LAP'].value_counts().to_dict()}\")\n",
    "\n",
    "# 3. Padronizar FL_CONTROLE_ESPECIAL_IMPRESSAO: -1/2 → 0/1\n",
    "if \"FL_CONTROLE_ESPECIAL_IMPRESSAO\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"FL_CONTROLE_ESPECIAL_IMPRESSAO\"] = (\n",
    "        df_pedidos_fil[\"FL_CONTROLE_ESPECIAL_IMPRESSAO\"]\n",
    "        .astype(str)\n",
    "        .replace({\"-1\": \"0\", \"2\": \"1\"})\n",
    "    )\n",
    "    print(f\"FL_CONTROLE_ESPECIAL_IMPRESSAO: {df_pedidos_fil['FL_CONTROLE_ESPECIAL_IMPRESSAO'].value_counts().to_dict()}\")\n",
    "\n",
    "# 4. Converter tipos numéricos\n",
    "cols_int = [\"FL_LAP_INTERNO\", \"FL_LAP_NO_COMPR\", \"FL_PROLONG_LAP\", \"QT_ARRANJO\", \"QT_NRCORES\"]\n",
    "for col in cols_int:\n",
    "    if col in df_pedidos_fil.columns:\n",
    "        df_pedidos_fil[col] = pd.to_numeric(df_pedidos_fil[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "print(\"\\n✅ Padronização de valores concluída\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-header",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "### 6.1. Features de Produto (compatíveis com ITENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "features-produto",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_TEM_LAP: {0: 160826, 1: 69717}\n",
      "  % com LAP: 30.2%\n",
      "\n",
      "SCORE_QUALIDADE: {0: 3090, 1: 8374, 2: 9569, 3: 209510}\n",
      "  Média: 2.85\n",
      "\n",
      "TX_ONDA_TIPO - Top 10:\n",
      "TX_ONDA_TIPO\n",
      "A3     67242\n",
      "A10    36599\n",
      "A2     32780\n",
      "A1     30459\n",
      "A12    14990\n",
      "A15    11830\n",
      "A18     7167\n",
      "B2      6664\n",
      "B1      5937\n",
      "A4      4621\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RAZAO_COMP_LARG:\n",
      "  Média: 2.58\n",
      "  Min/Max: 0.27 / 6.30\n",
      "\n",
      "FL_EXIG_PESOCAIXA: {1: 219697, 0: 10846}\n",
      "\n",
      "SCORE_COMPLEXIDADE:\n",
      "  Média: 0.82\n",
      "  Min/Max: 0.00 / 1.67\n"
     ]
    }
   ],
   "source": [
    "# 1. FL_TEM_LAP - Indicador de presença de LAP\n",
    "df_pedidos_fil[\"FL_TEM_LAP\"] = (\n",
    "    (df_pedidos_fil.get(\"FL_LAP_INTERNO\", 0) > 0) |\n",
    "    (df_pedidos_fil.get(\"FL_LAP_NO_COMPR\", 0) > 0) |\n",
    "    (df_pedidos_fil.get(\"FL_PROLONG_LAP\", 0) > 0)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"FL_TEM_LAP: {df_pedidos_fil['FL_TEM_LAP'].value_counts().to_dict()}\")\n",
    "print(f\"  % com LAP: {df_pedidos_fil['FL_TEM_LAP'].mean()*100:.1f}%\")\n",
    "\n",
    "# 2. SCORE_QUALIDADE (0-3 para PEDIDOS - menos campos que ITENS)\n",
    "df_pedidos_fil[\"SCORE_QUALIDADE\"] = (\n",
    "    df_pedidos_fil.get(\"FL_TESTE_EXIGELAUDO\", 0).astype(int) +\n",
    "    (df_pedidos_fil.get(\"VL_TESTE_COBB_INT_MAX\", 0) > 0).astype(int) +\n",
    "    (df_pedidos_fil.get(\"VL_TESTE_GRAMATURA\", 0) > 0).astype(int)\n",
    ")\n",
    "\n",
    "print(f\"\\nSCORE_QUALIDADE: {df_pedidos_fil['SCORE_QUALIDADE'].value_counts().sort_index().to_dict()}\")\n",
    "print(f\"  Média: {df_pedidos_fil['SCORE_QUALIDADE'].mean():.2f}\")\n",
    "\n",
    "# 3. TX_ONDA_TIPO - Extração do tipo de onda\n",
    "if \"CAT_COMPOSICAO\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"TX_ONDA_TIPO\"] = (\n",
    "        df_pedidos_fil[\"CAT_COMPOSICAO\"]\n",
    "        .astype(str)\n",
    "        .str.extract(r'^([A-Z]+\\d*)', expand=False)\n",
    "    )\n",
    "    print(f\"\\nTX_ONDA_TIPO - Top 10:\")\n",
    "    print(df_pedidos_fil[\"TX_ONDA_TIPO\"].value_counts().head(10))\n",
    "\n",
    "# 4. RAZAO_COMP_LARG - Razão dimensional\n",
    "if \"VL_COMPRIMENTO\" in df_pedidos_fil.columns and \"VL_LARGURA\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"RAZAO_COMP_LARG\"] = (\n",
    "        df_pedidos_fil[\"VL_COMPRIMENTO\"] / df_pedidos_fil[\"VL_LARGURA\"]\n",
    "    ).replace([np.inf, -np.inf], np.nan)\n",
    "    print(f\"\\nRAZAO_COMP_LARG:\")\n",
    "    print(f\"  Média: {df_pedidos_fil['RAZAO_COMP_LARG'].mean():.2f}\")\n",
    "    print(f\"  Min/Max: {df_pedidos_fil['RAZAO_COMP_LARG'].min():.2f} / {df_pedidos_fil['RAZAO_COMP_LARG'].max():.2f}\")\n",
    "\n",
    "# 5. FL_EXIG_PESOCAIXA\n",
    "if \"VL_PESOCAIXA\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"FL_EXIG_PESOCAIXA\"] = (df_pedidos_fil[\"VL_PESOCAIXA\"] > 0).astype(int)\n",
    "    print(f\"\\nFL_EXIG_PESOCAIXA: {df_pedidos_fil['FL_EXIG_PESOCAIXA'].value_counts().to_dict()}\")\n",
    "\n",
    "# 6. SCORE_COMPLEXIDADE (adaptado - sem vincos que não existem em PEDIDOS)\n",
    "df_pedidos_fil[\"SCORE_COMPLEXIDADE\"] = (\n",
    "    df_pedidos_fil.get(\"QT_NRCORES\", 0) +\n",
    "    df_pedidos_fil[\"SCORE_QUALIDADE\"] +\n",
    "    df_pedidos_fil[\"FL_TEM_LAP\"] * 2 +\n",
    "    (df_pedidos_fil.get(\"FL_CONTROLE_ESPECIAL_IMPRESSAO\", \"0\") == \"1\").astype(int) * 2\n",
    ") / 6  # divisor ajustado\n",
    "\n",
    "print(f\"\\nSCORE_COMPLEXIDADE:\")\n",
    "print(f\"  Média: {df_pedidos_fil['SCORE_COMPLEXIDADE'].mean():.2f}\")\n",
    "print(f\"  Min/Max: {df_pedidos_fil['SCORE_COMPLEXIDADE'].min():.2f} / {df_pedidos_fil['SCORE_COMPLEXIDADE'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-pedido-header",
   "metadata": {},
   "source": [
    "### 6.2. Features Específicas de PEDIDOS\n",
    "\n",
    "Features únicas relacionadas às características do pedido (não existem em ITENS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "features-pedido",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VL_AMPLITUDE_QTD:\n",
      "  Média: 1278 unidades\n",
      "  Mediana: 800 unidades\n",
      "\n",
      "VL_FLEXIBILIDADE_PCT:\n",
      "  Média: 11.0%\n",
      "\n",
      "FL_TEM_FLEXIBILIDADE: 100.0% dos pedidos têm flexibilidade\n",
      "\n",
      "TAMANHO_PEDIDO:\n",
      "TAMANHO_PEDIDO\n",
      "GRANDE          123609\n",
      "MEDIO            55726\n",
      "MUITO_GRANDE     50536\n",
      "PEQUENO            672\n",
      "Name: count, dtype: int64\n",
      "\n",
      "QT_PEDIDOS_ITEM_COMPOSICAO:\n",
      "  Média: 231.7 pedidos\n",
      "  Max: 2742 pedidos\n",
      "\n",
      "✅ Features específicas de PEDIDOS criadas\n"
     ]
    }
   ],
   "source": [
    "# 1. VL_AMPLITUDE_QTD - Flexibilidade de quantidade\n",
    "if all(col in df_pedidos_fil.columns for col in [\"QT_PEDIDAMAX\", \"QT_PEDIDAMIN\"]):\n",
    "    df_pedidos_fil[\"VL_AMPLITUDE_QTD\"] = (\n",
    "        df_pedidos_fil[\"QT_PEDIDAMAX\"] - df_pedidos_fil[\"QT_PEDIDAMIN\"]\n",
    "    )\n",
    "    print(f\"VL_AMPLITUDE_QTD:\")\n",
    "    print(f\"  Média: {df_pedidos_fil['VL_AMPLITUDE_QTD'].mean():.0f} unidades\")\n",
    "    print(f\"  Mediana: {df_pedidos_fil['VL_AMPLITUDE_QTD'].median():.0f} unidades\")\n",
    "\n",
    "# 2. VL_FLEXIBILIDADE_PCT - Amplitude como % da quantidade pedida\n",
    "if \"QT_PEDIDA\" in df_pedidos_fil.columns and \"VL_AMPLITUDE_QTD\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"VL_FLEXIBILIDADE_PCT\"] = (\n",
    "        (df_pedidos_fil[\"VL_AMPLITUDE_QTD\"] / df_pedidos_fil[\"QT_PEDIDA\"]) * 100\n",
    "    ).replace([np.inf, -np.inf], np.nan)\n",
    "    print(f\"\\nVL_FLEXIBILIDADE_PCT:\")\n",
    "    print(f\"  Média: {df_pedidos_fil['VL_FLEXIBILIDADE_PCT'].mean():.1f}%\")\n",
    "\n",
    "# 3. FL_TEM_FLEXIBILIDADE - Flag binária\n",
    "if \"VL_AMPLITUDE_QTD\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"FL_TEM_FLEXIBILIDADE\"] = (\n",
    "        df_pedidos_fil[\"VL_AMPLITUDE_QTD\"] > 0\n",
    "    ).astype(int)\n",
    "    pct_flex = df_pedidos_fil[\"FL_TEM_FLEXIBILIDADE\"].mean() * 100\n",
    "    print(f\"\\nFL_TEM_FLEXIBILIDADE: {pct_flex:.1f}% dos pedidos têm flexibilidade\")\n",
    "\n",
    "# 4. TAMANHO_PEDIDO - Classificação por faixas\n",
    "if \"QT_PEDIDA\" in df_pedidos_fil.columns:\n",
    "    df_pedidos_fil[\"TAMANHO_PEDIDO\"] = pd.cut(\n",
    "        df_pedidos_fil[\"QT_PEDIDA\"],\n",
    "        bins=[0, 1000, 5000, 15000, np.inf],\n",
    "        labels=[\"PEQUENO\", \"MEDIO\", \"GRANDE\", \"MUITO_GRANDE\"]\n",
    "    )\n",
    "    print(f\"\\nTAMANHO_PEDIDO:\")\n",
    "    print(df_pedidos_fil[\"TAMANHO_PEDIDO\"].value_counts())\n",
    "\n",
    "# 5. QT_PEDIDOS_ITEM_COMPOSICAO - Popularidade da combinação item+composição\n",
    "if all(col in df_pedidos_fil.columns for col in [\"CD_ITEM\", \"CAT_COMPOSICAO\", \"CD_PEDIDO\"]):\n",
    "    df_pedidos_fil[\"QT_PEDIDOS_ITEM_COMPOSICAO\"] = df_pedidos_fil.groupby(\n",
    "        [\"CD_ITEM\", \"CAT_COMPOSICAO\"]\n",
    "    )[\"CD_PEDIDO\"].transform(\"nunique\")\n",
    "    print(f\"\\nQT_PEDIDOS_ITEM_COMPOSICAO:\")\n",
    "    print(f\"  Média: {df_pedidos_fil['QT_PEDIDOS_ITEM_COMPOSICAO'].mean():.1f} pedidos\")\n",
    "    print(f\"  Max: {df_pedidos_fil['QT_PEDIDOS_ITEM_COMPOSICAO'].max()} pedidos\")\n",
    "\n",
    "print(\"\\n✅ Features específicas de PEDIDOS criadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate-header",
   "metadata": {},
   "source": [
    "## 7. Validação e Qualidade dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VALIDAÇÃO DA QUALIDADE DOS DADOS\n",
      "================================================================================\n",
      "\n",
      "1. RESUMO GERAL:\n",
      "  Total de registros: 230,543\n",
      "  Total de colunas: 69\n",
      "  Pedidos únicos: 230,076\n",
      "  Itens únicos: 7,623\n",
      "\n",
      "2. VALORES NULOS:\n",
      "  ✅ Nenhuma coluna com valores nulos\n",
      "\n",
      "3. DUPLICATAS:\n",
      "  Linhas completamente duplicadas: 0\n",
      "  Duplicatas CD_PEDIDO + CD_ITEM: 0\n",
      "\n",
      "4. FEATURES DERIVADAS:\n",
      "                               count         mean          std  min  \\\n",
      "FL_TEM_LAP                  230543.0     0.302403     0.459300  0.0   \n",
      "SCORE_QUALIDADE             230543.0     2.845638     0.532541  0.0   \n",
      "SCORE_COMPLEXIDADE          230543.0     0.821298     0.219616  0.0   \n",
      "VL_AMPLITUDE_QTD            230543.0  1278.027669  1476.941071  0.0   \n",
      "FL_TEM_FLEXIBILIDADE        230543.0     0.999510     0.022134  0.0   \n",
      "QT_PEDIDOS_ITEM_COMPOSICAO  230543.0   231.737650   355.670276  1.0   \n",
      "\n",
      "                                   25%         50%     75%           max  \n",
      "FL_TEM_LAP                    0.000000    0.000000     1.0      1.000000  \n",
      "SCORE_QUALIDADE               3.000000    3.000000     3.0      3.000000  \n",
      "SCORE_COMPLEXIDADE            0.666667    0.666667     1.0      1.666667  \n",
      "VL_AMPLITUDE_QTD            432.000000  800.000000  1536.0  33120.000000  \n",
      "FL_TEM_FLEXIBILIDADE          1.000000    1.000000     1.0      1.000000  \n",
      "QT_PEDIDOS_ITEM_COMPOSICAO   39.000000  119.000000   283.0   2742.000000  \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VALIDAÇÃO DA QUALIDADE DOS DADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Resumo geral\n",
    "print(f\"\\n1. RESUMO GERAL:\")\n",
    "print(f\"  Total de registros: {len(df_pedidos_fil):,}\")\n",
    "print(f\"  Total de colunas: {df_pedidos_fil.shape[1]}\")\n",
    "print(f\"  Pedidos únicos: {df_pedidos_fil['CD_PEDIDO'].nunique():,}\")\n",
    "print(f\"  Itens únicos: {df_pedidos_fil['CD_ITEM'].nunique():,}\")\n",
    "\n",
    "# 2. Valores nulos\n",
    "print(f\"\\n2. VALORES NULOS:\")\n",
    "nulos = df_pedidos_fil.isnull().sum()\n",
    "nulos_pct = (nulos / len(df_pedidos_fil) * 100).round(2)\n",
    "colunas_com_nulos = nulos[nulos > 0].sort_values(ascending=False)\n",
    "\n",
    "if len(colunas_com_nulos) > 0:\n",
    "    print(f\"  Colunas com nulos ({len(colunas_com_nulos)}):\")\n",
    "    for col in colunas_com_nulos.index[:10]:\n",
    "        print(f\"    {col}: {nulos[col]:,} ({nulos_pct[col]:.1f}%)\")\n",
    "else:\n",
    "    print(\"  ✅ Nenhuma coluna com valores nulos\")\n",
    "\n",
    "# 3. Duplicatas\n",
    "print(f\"\\n3. DUPLICATAS:\")\n",
    "duplicatas_completas = df_pedidos_fil.duplicated().sum()\n",
    "print(f\"  Linhas completamente duplicadas: {duplicatas_completas:,}\")\n",
    "\n",
    "# Duplicatas por chave composta\n",
    "if \"CD_PEDIDO\" in df_pedidos_fil.columns and \"CD_ITEM\" in df_pedidos_fil.columns:\n",
    "    duplicatas_chave = df_pedidos_fil.duplicated(subset=[\"CD_PEDIDO\", \"CD_ITEM\"]).sum()\n",
    "    print(f\"  Duplicatas CD_PEDIDO + CD_ITEM: {duplicatas_chave:,}\")\n",
    "\n",
    "# 4. Estatísticas descritivas das features derivadas\n",
    "print(f\"\\n4. FEATURES DERIVADAS:\")\n",
    "features_derivadas = [\n",
    "    \"FL_TEM_LAP\", \"SCORE_QUALIDADE\", \"SCORE_COMPLEXIDADE\",\n",
    "    \"VL_AMPLITUDE_QTD\", \"FL_TEM_FLEXIBILIDADE\", \"QT_PEDIDOS_ITEM_COMPOSICAO\"\n",
    "]\n",
    "features_existentes = [f for f in features_derivadas if f in df_pedidos_fil.columns]\n",
    "print(df_pedidos_fil[features_existentes].describe().T)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 8. Exportação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPORTAÇÃO CONCLUÍDA\n",
      "================================================================================\n",
      "Arquivo: ../../../data/ml/tb_pedidos_sumarizado.parquet\n",
      "Tamanho: 11.20 MB\n",
      "Registros: 230,543\n",
      "Colunas: 69\n",
      "\n",
      "✅ Tabela pronta para merge com TAREFCON\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Caminho de saída\n",
    "output_path = \"../../../data/ml/tb_pedidos_sumarizado.parquet\"\n",
    "\n",
    "# Garantir que diretório existe\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Salvar\n",
    "df_pedidos_fil.to_parquet(output_path, index=False)\n",
    "\n",
    "# Tamanho do arquivo\n",
    "file_size_mb = os.path.getsize(output_path) / 1024**2\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPORTAÇÃO CONCLUÍDA\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Arquivo: {output_path}\")\n",
    "print(f\"Tamanho: {file_size_mb:.2f} MB\")\n",
    "print(f\"Registros: {len(df_pedidos_fil):,}\")\n",
    "print(f\"Colunas: {df_pedidos_fil.shape[1]}\")\n",
    "print(\"\\n✅ Tabela pronta para merge com TAREFCON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 9. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMO DO PROCESSAMENTO\n",
      "================================================================================\n",
      "\n",
      "Dados originais:\n",
      "  Registros: 406,890\n",
      "  Colunas: 87\n",
      "\n",
      "Dados processados:\n",
      "  Registros: 230,543\n",
      "  Colunas: 69\n",
      "\n",
      "Redução:\n",
      "  Registros: 43.3%\n",
      "  Colunas: 20.7%\n",
      "\n",
      "Features criadas:\n",
      "  ✅ FL_TEM_LAP\n",
      "  ✅ SCORE_QUALIDADE\n",
      "  ✅ TX_ONDA_TIPO\n",
      "  ✅ RAZAO_COMP_LARG\n",
      "  ✅ FL_EXIG_PESOCAIXA\n",
      "  ✅ SCORE_COMPLEXIDADE\n",
      "  ✅ VL_AMPLITUDE_QTD\n",
      "  ✅ VL_FLEXIBILIDADE_PCT\n",
      "  ✅ FL_TEM_FLEXIBILIDADE\n",
      "  ✅ TAMANHO_PEDIDO\n",
      "  ✅ QT_PEDIDOS_ITEM_COMPOSICAO\n",
      "\n",
      "================================================================================\n",
      "PROCESSAMENTO CONCLUÍDO COM SUCESSO!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMO DO PROCESSAMENTO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nDados originais:\")\n",
    "print(f\"  Registros: {df_pedidos.shape[0]:,}\")\n",
    "print(f\"  Colunas: {df_pedidos.shape[1]}\")\n",
    "\n",
    "print(f\"\\nDados processados:\")\n",
    "print(f\"  Registros: {df_pedidos_fil.shape[0]:,}\")\n",
    "print(f\"  Colunas: {df_pedidos_fil.shape[1]}\")\n",
    "\n",
    "reducao_reg = (1 - df_pedidos_fil.shape[0]/df_pedidos.shape[0])*100\n",
    "reducao_cols = (1 - df_pedidos_fil.shape[1]/df_pedidos.shape[1])*100\n",
    "\n",
    "print(f\"\\nRedução:\")\n",
    "print(f\"  Registros: {reducao_reg:.1f}%\")\n",
    "print(f\"  Colunas: {reducao_cols:.1f}%\")\n",
    "\n",
    "print(f\"\\nFeatures criadas:\")\n",
    "features_novas = [\n",
    "    \"FL_TEM_LAP\", \"SCORE_QUALIDADE\", \"TX_ONDA_TIPO\", \"RAZAO_COMP_LARG\",\n",
    "    \"FL_EXIG_PESOCAIXA\", \"SCORE_COMPLEXIDADE\", \"VL_AMPLITUDE_QTD\",\n",
    "    \"VL_FLEXIBILIDADE_PCT\", \"FL_TEM_FLEXIBILIDADE\", \"TAMANHO_PEDIDO\",\n",
    "    \"QT_PEDIDOS_ITEM_COMPOSICAO\"\n",
    "]\n",
    "existentes = [f for f in features_novas if f in df_pedidos_fil.columns]\n",
    "for feat in existentes:\n",
    "    print(f\"  ✅ {feat}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"PROCESSAMENTO CONCLUÍDO COM SUCESSO!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
