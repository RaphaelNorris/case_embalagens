# ğŸ§¹ PrÃ©-processamento e Limpeza de Dados

Esta pasta contÃ©m notebooks de **preparaÃ§Ã£o, limpeza e transformaÃ§Ã£o de dados** para anÃ¡lise e modelagem.

## ğŸ“ Estrutura

| Notebook | Foco | DescriÃ§Ã£o |
|----------|------|-----------|
| `20.0-rn-preprocessing-refined-20240101.ipynb` | Camada Refined | PreparaÃ§Ã£o de dados para camada analÃ­tica (Gold) |
| `20.1-rn-preprocessing-tables-20240101.ipynb` | MÃºltiplas Tabelas | Limpeza e padronizaÃ§Ã£o de todas as tabelas |

## ğŸ¯ Objetivo

Transformar dados **brutos** (Raw/Trusted) em dados **limpos e estruturados** (Refined/ML) prontos para:

1. **AnÃ¡lise AnalÃ­tica** (BI, dashboards)
2. **Machine Learning** (features engineeradas)
3. **ProduÃ§Ã£o** (dados validados e confiÃ¡veis)

## ğŸ”„ Pipeline de Processamento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¥‰ Raw    â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ¥ˆ Trusted  â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ§¹ Clean   â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ¥‡ Gold  â”‚
â”‚  (Bronze)   â”‚     â”‚   (Silver)   â”‚     â”‚ (Processo)  â”‚     â”‚ (Refined) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ExtraÃ§Ã£o           ValidaÃ§Ã£o            TransformaÃ§Ã£o       Consumo
```

## ğŸ“Š OperaÃ§Ãµes de PrÃ©-processamento

### 1. Limpeza de Dados

**Valores Ausentes**:
- IdentificaÃ§Ã£o de padrÃµes de missingness
- ImputaÃ§Ã£o estratÃ©gica (mÃ©dia, mediana, forward-fill)
- DocumentaÃ§Ã£o de decisÃµes

**Duplicados**:
- DetecÃ§Ã£o de registros duplicados
- AnÃ¡lise de chaves compostas
- RemoÃ§Ã£o ou marcaÃ§Ã£o

**Outliers**:
- DetecÃ§Ã£o (IQR, Z-score, isolationforest)
- AnÃ¡lise de impacto
- Tratamento ou remoÃ§Ã£o

### 2. TransformaÃ§Ãµes

**Tipos de Dados**:
- ConversÃ£o de tipos (str â†’ numeric, str â†’ datetime)
- PadronizaÃ§Ã£o de formatos
- Encoding categÃ³rico

**NormalizaÃ§Ã£o**:
- Strings (uppercase, trim, remove special chars)
- NÃºmeros (scaling, normalization)
- Datas (timezone, formato padrÃ£o)

**DerivaÃ§Ãµes**:
- Colunas calculadas
- Flags booleanas
- Categorias derivadas

### 3. Enriquecimento

**RelaÃ§Ãµes**:
- InferÃªncia de chaves faltantes
- PropagaÃ§Ã£o de dados (ex: cliente â†’ pedido)
- Joins e merges

**Features**:
- AgregaÃ§Ãµes
- EstatÃ­sticas mÃ³veis
- Lags temporais

## ğŸ› ï¸ FunÃ§Ãµes Implementadas

Baseado nas limpezas realizadas, foram criadas funÃ§Ãµes em:

### `src/data/data_treatment.py`
```python
corrigir_tarefcon_relacoes(df_tarefcon)
# Infere ID_PEDIDO e ID_ITEM a partir de CD_OP
# Propaga ID_IDCLIENTE
```

### `src/analysis/data_processing.py`
```python
clean_numeric_and_categorical(df, threshold=0.9)
# Classifica colunas em numÃ©ricas ou categÃ³ricas
# Preenche missing values
```

### `src/features/build_features.py`
```python
create_temporal_features(df, datetime_col)
# Extrai year, month, day, day_of_week, etc.

create_production_features(df, group_cols)
# Rolling means, lags, agregaÃ§Ãµes
```

## ğŸ“‹ Checklist de Qualidade

Para cada tabela processada, verificar:

- [ ] **Tipos de dados corretos**
- [ ] **Sem valores ausentes crÃ­ticos**
- [ ] **Sem duplicados nÃ£o intencionais**
- [ ] **Outliers tratados ou documentados**
- [ ] **RelaÃ§Ãµes validadas**
- [ ] **Datas no formato correto**
- [ ] **Strings padronizadas**
- [ ] **Features derivadas criadas**

## ğŸ” Como Usar

1. **PrÃ©-requisitos**:
   - Dados na camada Trusted (02 - trusted/)
   - Insights da anÃ¡lise exploratÃ³ria (01-eda-tables, 02-eda-cross)

2. Execute na ordem:
   ```bash
   cd project_data_science/notebooks/03-preprocessing
   jupyter lab

   # Execute primeiro:
   20.0-rn-preprocessing-refined-20240101.ipynb

   # Depois:
   20.1-rn-preprocessing-tables-20240101.ipynb
   ```

3. Dados limpos serÃ£o salvos em:
   - `data/03 - ml/`: Features para ML
   - `data/04 - refined/`: Dados analÃ­ticos

## ğŸ’¡ DecisÃµes de PrÃ©-processamento

### Status das Facas
- **Problema**: CÃ³digos numÃ©ricos como string ("1.0", "2.0")
- **SoluÃ§Ã£o**: ConversÃ£o para int, mapeamento para labels
- **FunÃ§Ã£o**: `canonical_status_code()` em dashboard_facas.py

### CD_OP em TarefCon
- **Problema**: Formato nÃ£o estruturado "PEDIDO/ITEM"
- **SoluÃ§Ã£o**: Parsing e inferÃªncia de ID_PEDIDO e ID_ITEM
- **FunÃ§Ã£o**: `corrigir_tarefcon_relacoes()` em data_treatment.py

### Valores NumÃ©ricos
- **Problema**: Colunas numÃ©ricas como string
- **SoluÃ§Ã£o**: CoerÃ§Ã£o com threshold (90% numÃ©ricos)
- **FunÃ§Ã£o**: `clean_numeric_and_categorical()` em data_processing.py

## ğŸ“Š MÃ©tricas de Qualidade

ApÃ³s prÃ©-processamento, os dados devem ter:

| MÃ©trica | Target | Justificativa |
|---------|--------|---------------|
| Missing Values | < 5% | Dados completos para anÃ¡lise |
| Duplicados | 0% | Integridade dos dados |
| Tipos Incorretos | 0% | Processamento sem erros |
| Outliers Extremos | < 1% | Dados representativos |

## ğŸ”— PrÃ³ximos Passos

ApÃ³s prÃ©-processamento:
- **04-production/**: Aplicar em produÃ§Ã£o
- **Modelagem**: Treinar modelos ML
- **Dashboards**: VisualizaÃ§Ã£o dos dados limpos

## ğŸ“š ReferÃªncias

- [Data Cleaning Best Practices](https://github.com/sfbrigade/data-science-wg/blob/master/dswg_project_resources/Data-Cleaning-Best-Practices.md)
- [Pandas Data Cleaning](https://pandas.pydata.org/docs/user_guide/missing_data.html)
- [Feature Engineering Guide](https://www.kaggle.com/learn/feature-engineering)
