"""
OpenAI Insights Module
=====================

This module provides AI-powered insights for production productivity predictions
using OpenAI's GPT models to generate contextual analysis and recommendations.
"""

from typing import Any, Dict, List, Optional, Tuple

import openai
import pandas as pd
import streamlit as st


# Default API key provided by user for fallback usage in the Streamlit UI
DEFAULT_OPENAI_API_KEY = (
    "sk-proj-2_-R0BMnvyJawABVunxuJdA6yqiHvAOWhCp8181kfJcXMGvcersBdT_Sw_Fawxd-"
    "HNH6QogwGCT3BlbkFJy-n7w0-C2yL6hjhmTXru2NuVBAUElu9dmVc1jvbNIds2oam_Vq9hgq7q4QMzRdDYwQerxO1IgA"
)

INSIGHTS_PERSONA_DESCRIPTION = (
    "Identidade: voc√™ √© um Analista de Performance Industrial que domina o processo de convers√£o na Adami (flexo e corte & vinco) "
    "e transforma outputs do modelo em recomenda√ß√µes pr√°ticas para comercial, produ√ß√£o, desenvolvimento e diretoria. "
    "Contexto que voc√™ domina: trade-offs t√©cnicos vs. velocidade, din√¢mica comercial (precifica√ß√£o/competitividade), limita√ß√µes de ch√£o de f√°brica "
    "e argumentos t√©cnicos de PCP. Sua miss√£o: traduzir as predi√ß√µes em decis√µes acion√°veis (aceitar/recusar/ajustar pre√ßo, priorizar projetos, justificar capacidade), "
    "sempre quantificando em caixas/hora, custo de tempo de m√°quina ou impacto financeiro. "
    "Princ√≠pios de comunica√ß√£o: traduza linguagem estat√≠stica em impacto operacional, contextualize no processo f√≠sico, quantifique em termos pr√°ticos, "
    "priorize acionabilidade, trate incertezas explicitamente e destaque limita√ß√µes n√£o modeladas. "
    "Regras de ouro: nunca use jarg√£o estat√≠stico sem explicar, diferencie flexo vs corte & vinco quando relevante, conecte achados √†s etapas f√≠sicas, "
    "seja honesto sobre vari√°veis n√£o modeladas e aplique exemplos num√©ricos realistas do contexto Adami."
)

PROJECT_CONTEXT = (
    "Contexto de neg√≥cio: Adami, fabricante de embalagens de papel√£o ondulado, enfrenta precifica√ß√£o por quilo que ignora produtividade, "
    "resultando em perda de itens produtivos (5k‚Äì30k cx/h) para concorrentes, sobrecarga de itens improdutivos e impossibilidade de precificar o tempo de m√°quina. "
    "Impacto financeiro: margem perdida em itens produtivos vendidos abaixo do valor, custos operacionais altos em itens improdutivos e recusa de pedidos "
    "que poderiam ser lucrativos. Meta do modelo: classificar itens como PRODUTIVOS/IMPRODUTIVOS na convers√£o, estimar caixas/hora e identificar as principais features "
    "dimensionais, tipo de onda (B, C, D, BC, DC), gramaturas, n√∫mero de cores, arranjos e tratamentos (furos, al√ßas, janelas, resina) que impactam produtividade. "
    "Decis√µes habilitadas: (1) Comercial ‚Äì aceitar/recusar or√ßamentos ou ajustar pre√ßo; (2) Desenvolvimento ‚Äì priorizar projetos com melhor perfil produtivo; "
    "(3) Produ√ß√£o ‚Äì argumentar capacidade e sequenciamento; (4) Financeiro ‚Äì precificar incluindo custo de ocupa√ß√£o. "
    "Caracter√≠sticas do processo: etapa de convers√£o (chapa ‚Üí caixa acabada); flexo produz 1 chapa/caixa, corte & vinco usa m√∫ltiplas caixas por ciclo e ferramental. "
    "Ru√≠dos conhecidos: qualidade vari√°vel da chapa, desgaste de ferramental, varia√ß√£o entre operadores e pequenas diferen√ßas de mat√©ria-prima. "
    "Stakeholders: comercial quer argumentos para precificar, produ√ß√£o busca performance, desenvolvimento avalia viabilidade, diretoria quer competitividade/margem. "
    "Cen√°rio atual sem modelo: decis√µes emp√≠ricas, recusas por achismo, falta de argumentos quantitativos e impossibilidade de estimar produtividade em desenvolvimento. "
    "Frequ√™ncia de uso: di√°rio (precifica√ß√£o), semanal (novos itens), mensal/trimestral (revis√µes). "
    "Incerteza: quando faltam dados ou h√° variabilidade alta, destacar intervalos e sugerir pilotos/lotes conservadores; reconhecer efeitos n√£o modelados (desgaste de faca etc.)."
)


class ProductivityInsightsGenerator:
    """Generate AI-powered insights for productivity predictions."""

    def __init__(self, api_key: str, model: str = "gpt-4o"):
        """Initialize the insights generator.

        Parameters
        ----------
        api_key : str
            OpenAI API key
        model : str
            OpenAI model to use for generating insights
        """
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model

    def generate_prediction_insights(
        self,
        prediction_data: Dict[str, Any],
        machine_type: str,
        input_features: Dict[str, Any],
        top_features: Optional[List[Tuple[str, float]]] = None,
    ) -> str:
        """Generate insights for a single prediction.

        Parameters
        ----------
        prediction_data : dict
            Prediction results including probability and class
        machine_type : str
            Type of machine (flexo or cv)
        input_features : dict
            Input features used for prediction
        top_features : list, optional
            Top contributing features with their SHAP values

        Returns
        -------
        str
            Generated insights text
        """
        context = self._prepare_context(
            prediction_data, machine_type, input_features, top_features
        )

        prompt = f"""
        CONTEXTO OPERACIONAL DA ADAMI:
        {context}

        SOBRE O PROJETO:
        {PROJECT_CONTEXT}

        Escreva em texto puro (sem negrito, it√°lico ou marca√ß√£o Markdown) e siga este template:
        Resumo Executivo: s√≠ntese em at√© 3 frases sobre a predi√ß√£o e impacto.
        Drivers Principais: listar at√© 5 fatores com explica√ß√£o curta.
        A√ß√µes Priorit√°rias: tr√™s recomenda√ß√µes numeradas, orientadas a opera√ß√£o/fabrica√ß√£o.
        Riscos e Oportunidades: separar em Riscos e Oportunidades com bullets simples.
        Pr√≥ximos Passos: at√© 3 passos com respons√°veis sugeridos e horizonte temporal.

        Reforce a conex√£o com custo, prazo, consumo de papel/celulose e metas ESG sempre que fizer sentido.
        """

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            f"{INSIGHTS_PERSONA_DESCRIPTION} "
                            "Use linguagem clara, objetiva e orientada a ganhos operacionais. "
                            "Mantenha foco em produtividade, estabilidade da linha flexo/CV e responsabilidade ambiental."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                max_completion_tokens=2000,
            )

            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"Erro ao gerar insights: {str(e)}"
            print(f"[OpenAI Insights] {error_msg}")
            return error_msg

    def generate_batch_insights(
        self, results_df: pd.DataFrame, machine_type: str
    ) -> str:
        """Generate insights for batch predictions.

        Parameters
        ----------
        results_df : pd.DataFrame
            DataFrame with prediction results
        machine_type : str
            Type of machine (flexo or cv)

        Returns
        -------
        str
            Generated batch insights text
        """
        total_orders = len(results_df)

        if "pred_m3_por_hora" in results_df.columns:
            avg_density = results_df["pred_m3_por_hora"].mean()
            median_density = results_df["pred_m3_por_hora"].median()
            density_p90 = results_df["pred_m3_por_hora"].quantile(0.9)
            piece_volume_mean = (
                results_df["volume_peca_m3"].mean()
                if "volume_peca_m3" in results_df.columns
                else None
            )
            total_volume_est = (
                results_df["volume_total_estimado_m3"].sum()
                if "volume_total_estimado_m3" in results_df.columns
                else None
            )
            total_time_str = "N/D"
            if "pred_tempo_horas" in results_df.columns:
                total_time = results_df["pred_tempo_horas"].sum()
                total_time_str = f"{total_time:,.2f}"

            piece_volume_str = (
                f"{piece_volume_mean:,.4f}" if piece_volume_mean is not None else "N/D"
            )
            total_volume_est_str = (
                f"{total_volume_est:,.2f}" if total_volume_est is not None else "N/D"
            )

            context = f"""
            AN√ÅLISE DE LOTE - M√ÅQUINA {machine_type.upper()}:
            - Total de pedidos: {total_orders}
            - m¬≥/h m√©dio: {avg_density:,.2f}
            - Mediana e P90: {median_density:,.2f} | {density_p90:,.2f}
            - Volume m√©dio por pe√ßa (m¬≥): {piece_volume_str}
            - Volume total estimado (m¬≥): {total_volume_est_str}
            - Tempo agregado projetado (h): {total_time_str}
            """

            prompt = f"""
            Analise este lote de estimativas de throughput (m¬≥/h) para a Adami e forne√ßa insights estrat√©gicos:

            {context}

            SOBRE O PROJETO:
            {PROJECT_CONTEXT}

            Escreva em texto puro (sem negrito/it√°lico). Estruture assim:
            Panorama do Lote: vis√£o macro com m√©tricas cr√≠ticas, gargalos e impacto em PCP/log√≠stica.
            Padr√µes Observados: bullets com correla√ß√µes entre clusters, throughput previsto e vari√°veis geom√©tricas.
            Prioridades de Atua√ß√£o: lista numerada destacando c√©lulas/m√°quinas/pedidos com maior potencial ou risco (considerando m¬≥/h e volume financeiro).
            Riscos e Oportunidades: duas listas simples (Riscos / Oportunidades) conectando com custo, atendimento e ESG.
            Plano de Monitoramento: sugest√µes objetivas de indicadores e cad√™ncia de acompanhamento.

            Utilize linguagem consultiva e direcione as recomenda√ß√µes para l√≠deres de produ√ß√£o, manuten√ß√£o e PCP.
            """
        else:
            high_prod_count = (results_df["classe_prevista"] == 1).sum()
            high_prod_rate = high_prod_count / total_orders
            avg_probability = results_df["prob_produtivo"].mean()

            low_prob_orders = results_df[results_df["prob_produtivo"] < 0.5]
            high_prob_orders = results_df[results_df["prob_produtivo"] > 0.8]

            context = f"""
            AN√ÅLISE DE LOTE - M√ÅQUINA {machine_type.upper()}:
            - Total de pedidos: {total_orders}
            - Pedidos com alta produtividade prevista: {high_prod_count} ({high_prod_rate:.1%})
            - Probabilidade m√©dia: {avg_probability:.1%}
            - Pedidos com baixa probabilidade (<50%): {len(low_prob_orders)}
            - Pedidos com alta probabilidade (>80%): {len(high_prob_orders)}
            """

            prompt = f"""
            Analise este lote de predi√ß√µes de produtividade industrial para a Adami e forne√ßa insights estrat√©gicos:

            {context}

            SOBRE O PROJETO:
            {PROJECT_CONTEXT}

            Escreva em texto puro (sem negrito/it√°lico). Estruture assim:
            Panorama do Lote: vis√£o macro com m√©tricas cr√≠ticas, gargalos e impacto em PCP/log√≠stica.
            Padr√µes Observados: bullets com correla√ß√µes entre clusters, classes e vari√°veis geom√©tricas.
            Prioridades de Atua√ß√£o: lista numerada destacando c√©lulas/m√°quinas/pedidos priorit√°rios e por qu√™.
            Riscos e Oportunidades: duas listas simples (Riscos / Oportunidades) conectando com custo, atendimento e ESG.
            Plano de Monitoramento: sugest√µes objetivas de indicadores e cad√™ncia de acompanhamento.

            Utilize linguagem consultiva e direcione as recomenda√ß√µes para l√≠deres de produ√ß√£o, manuten√ß√£o e PCP.
            """

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            f"{INSIGHTS_PERSONA_DESCRIPTION} "
                            "Foque em insights t√°ticos e estrat√©gicos para gestores de produ√ß√£o e PCP."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                max_completion_tokens=5000,
            )

            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"Erro ao gerar insights do lote: {str(e)}"
            print(f"[OpenAI Insights] {error_msg}")
            return error_msg

    def _prepare_context(
        self,
        prediction_data: Dict[str, Any],
        machine_type: str,
        input_features: Dict[str, Any],
        top_features: Optional[List[Tuple[str, float]]] = None,
    ) -> str:
        """Prepare context string for AI analysis."""

        prob = prediction_data.get("prob_produtivo")
        prediction = prediction_data.get("classe_prevista")
        predicted_density = prediction_data.get("pred_m3_por_hora")
        predicted_total = prediction_data.get("volume_total_estimado_m3")
        qt_pedida = prediction_data.get("qt_pedida")

        if predicted_density is not None:
            density_str = f"{predicted_density:,.2f}"
            total_str = (
                f"{predicted_total:,.2f}" if predicted_total is not None else "N/D"
            )
            context = f"""
            TIPO DE M√ÅQUINA: {machine_type.upper()}
            THROUGHPUT PREVISTO: {density_str} m¬≥/h
            VOLUME TOTAL ESTIMADO: {total_str} m¬≥
            QUANTIDADE PEDIDA: {qt_pedida if qt_pedida is not None else "N/D"}

            CARACTER√çSTICAS DO PEDIDO:
            """
        else:
            context = f"""
            TIPO DE M√ÅQUINA: {machine_type.upper()}
            PREDI√á√ÉO: {"Alta Produtividade" if prediction == 1 else "Baixa Produtividade"}
            PROBABILIDADE: {prob:.1% if prob is not None else "N/D"}

            CARACTER√çSTICAS DO PEDIDO:
            """

        for key, value in input_features.items():
            if key in ["VL_COMPRIMENTO", "VL_LARGURA", "VL_GRAMATURA"]:
                context += f"- {key}: {value} mm\n"
            elif key in ["QT_NRCORES", "QT_PEDIDA", "QT_ARRANJO"]:
                context += f"- {key}: {value}\n"
            else:
                context += f"- {key}: {value}\n"

        if top_features:
            context += "\nPRINCIPAIS FATORES INFLUENCIADORES:\n"
            for feature, importance in top_features[:5]:
                context += f"- {feature}: {importance:.3f}\n"

        cluster_cols = [
            k for k in prediction_data.keys() if k.startswith("PROB_CLUSTER_")
        ]
        if cluster_cols:
            context += "\nAN√ÅLISE DE CLUSTERS:\n"
            for col in cluster_cols:
                cluster_num = col.split("_")[-1]
                prob_cluster = prediction_data[col]
                context += f"- Cluster {cluster_num}: {prob_cluster:.1%}\n"

        return context


def get_openai_insights_component() -> Tuple[bool, Optional[str]]:
    """Create OpenAI configuration component in sidebar.

    Returns
    -------
    tuple
        (enable_insights, api_key) where enable_insights is bool and api_key is str or None
    """
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ü§ñ IA Insights")

    enable_insights = st.sidebar.checkbox(
        "Ativar Insights com IA", help="Gera an√°lises inteligentes usando OpenAI GPT"
    )

    api_key = None
    if enable_insights:
        api_key = st.sidebar.text_input(
            "OpenAI API Key",
            type="password",
            help="Insira sua chave da API OpenAI para ativar insights inteligentes",
        )

        if not api_key:
            if DEFAULT_OPENAI_API_KEY:
                st.sidebar.info("‚ÑπÔ∏è Usando API Key padr√£o pr√©-configurada.")
                api_key = DEFAULT_OPENAI_API_KEY
            else:
                st.sidebar.warning("‚ö†Ô∏è API Key necess√°ria para ativar insights")
                return False, None

    return enable_insights, api_key


def display_ai_insights(
    insights_generator: ProductivityInsightsGenerator,
    prediction_data: Dict[str, Any],
    machine_type: str,
    input_features: Dict[str, Any],
    top_features: Optional[List[Tuple[str, float]]] = None,
):
    """Display AI-generated insights in the Streamlit app.

    Parameters
    ----------
    insights_generator : ProductivityInsightsGenerator
        Configured insights generator
    prediction_data : dict
        Prediction results
    machine_type : str
        Type of machine
    input_features : dict
        Input features used for prediction
    top_features : list, optional
        Top contributing features
    """
    st.subheader("ü§ñ An√°lise Inteligente")

    with st.spinner("Gerando insights com IA..."):
        insights = insights_generator.generate_prediction_insights(
            prediction_data, machine_type, input_features, top_features
        )

    if not isinstance(insights, str) or not insights.strip():
        print(f"[OpenAI Insights] Resposta vazia ou inv√°lida: {insights!r}")
        st.warning("N√£o foi poss√≠vel gerar insights neste momento.")
        return
    if insights.strip().lower().startswith("erro ao gerar insights"):
        print(f"[OpenAI Insights] {insights}")
        st.error(insights)
        return
    if insights.strip().lower().startswith("n√£o foi poss√≠vel"):
        print(f"[OpenAI Insights] {insights}")
        st.warning(
            "N√£o foi poss√≠vel gerar insights neste momento. "
            "Verifique o console/logs para detalhes."
        )
        return

    st.markdown(
        f"""
    <div class="ai-insights">
        <div style="background: white; color: black; padding: 1rem; border-radius: 5px; margin-top: 1rem;">
            {insights.replace(chr(10), "<br>")}
        </div>
    </div>
    """,
        unsafe_allow_html=True,
    )


def display_batch_ai_insights(
    insights_generator: ProductivityInsightsGenerator,
    results_df: pd.DataFrame,
    machine_type: str,
):
    """Display AI-generated insights for batch predictions.

    Parameters
    ----------
    insights_generator : ProductivityInsightsGenerator
        Configured insights generator
    results_df : pd.DataFrame
        DataFrame with prediction results
    machine_type : str
        Type of machine
    """
    st.subheader("ü§ñ An√°lise Inteligente do Lote")

    with st.spinner("Gerando insights do lote com IA..."):
        insights = insights_generator.generate_batch_insights(results_df, machine_type)

    if not isinstance(insights, str) or not insights.strip():
        print(f"[OpenAI Insights] Resposta vazia ou inv√°lida (lote): {insights!r}")
        st.warning("N√£o foi poss√≠vel gerar insights para o lote neste momento.")
        return
    if insights.strip().lower().startswith("erro ao gerar insights"):
        print(f"[OpenAI Insights] {insights}")
        st.error(insights)
        return
    if insights.strip().lower().startswith("n√£o foi poss√≠vel"):
        print(f"[OpenAI Insights] {insights}")
        st.warning(
            "N√£o foi poss√≠vel gerar insights para o lote neste momento. "
            "Verifique o console/logs para detalhes."
        )
        return

    st.markdown(
        f"""
    <div class="ai-insights">
        <h4>üí° Insights Estrat√©gicos do Lote</h4>
            {insights.replace(chr(10), "<br>")}
        </div>
    </div>
    """,
        unsafe_allow_html=True,
    )
