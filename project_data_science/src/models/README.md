# ğŸ¤– Models Module

## PropÃ³sito
Treinamento, avaliaÃ§Ã£o e prediÃ§Ã£o de **modelos de Machine Learning**.

## MÃ³dulos

### ğŸ“ `train_model.py`
Treina e avalia modelos de ML para previsÃ£o de produÃ§Ã£o.

### ğŸ”® `predict_model.py`
Realiza prediÃ§Ãµes com modelos treinados.

---

## Treinamento de Modelos

### `train_production_model(X, y, model_type='random_forest', test_size=0.2, **model_params)`

Treina modelo de produÃ§Ã£o com validaÃ§Ã£o automÃ¡tica.

**Modelos disponÃ­veis:**
- `'random_forest'` â†’ RandomForestRegressor (padrÃ£o)
- `'xgboost'` â†’ XGBRegressor
- `'lightgbm'` â†’ LGBMRegressor

**Retorno:**
- `model`: Modelo treinado
- `metrics`: Dict com mÃ©tricas (MAE, RMSE, RÂ², MAPE)

**Exemplo:**
```python
from src.models.train_model import train_production_model
import pandas as pd

# 1. Carregar features
df = pd.read_parquet('data/03 - ml/production_features.parquet')

# 2. Preparar X e y
feature_cols = [
    'quantidade_lag_1', 'quantidade_lag_7',
    'quantidade_rolling_7d_mean', 'quantidade_rolling_7d_std',
    'year', 'month', 'day_of_week'
]
X = df[feature_cols]
y = df['quantidade']

# 3. Treinar Random Forest
model, metrics = train_production_model(
    X, y,
    model_type='random_forest',
    n_estimators=100,
    max_depth=10,
    random_state=42
)

print(f"âœ… MAE: {metrics['mae']:.2f}")
print(f"âœ… RMSE: {metrics['rmse']:.2f}")
print(f"âœ… RÂ²: {metrics['r2']:.2f}")
```

**ParÃ¢metros por modelo:**

**Random Forest:**
```python
model, metrics = train_production_model(
    X, y,
    model_type='random_forest',
    n_estimators=100,      # NÃºmero de Ã¡rvores
    max_depth=10,          # Profundidade mÃ¡xima
    min_samples_split=5,   # MÃ­nimo para split
    random_state=42
)
```

**XGBoost:**
```python
model, metrics = train_production_model(
    X, y,
    model_type='xgboost',
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
```

**LightGBM:**
```python
model, metrics = train_production_model(
    X, y,
    model_type='lightgbm',
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    num_leaves=31,
    random_state=42
)
```

---

### `save_model(model, model_name, metadata=None)`

Salva modelo treinado com metadados.

**Exemplo:**
```python
from src.models.train_model import save_model

metadata = {
    'model_type': 'random_forest',
    'features': feature_cols,
    'metrics': metrics,
    'trained_at': '2024-01-15',
    'data_version': 'v1.0'
}

save_model(model, 'production_model_v1', metadata)
# Salvo em: models/production_model_v1.pkl
```

---

### `load_model(model_name)`

Carrega modelo salvo.

**Exemplo:**
```python
from src.models.train_model import load_model

model = load_model('production_model_v1')
# Pronto para fazer prediÃ§Ãµes
```

---

## PrediÃ§Ãµes

### `predict_production(model, X)`

Realiza prediÃ§Ãµes com modelo treinado.

**Exemplo:**
```python
from src.models.predict_model import predict_production
import pandas as pd

# 1. Carregar modelo
model = load_model('production_model_v1')

# 2. Preparar dados novos
df_new = pd.read_parquet('data/03 - ml/production_features_new.parquet')
X_new = df_new[feature_cols]

# 3. Predizer
predictions = predict_production(model, X_new)

# 4. Adicionar ao DataFrame
df_new['quantidade_prevista'] = predictions
df_new[['dt_inicio', 'quantidade', 'quantidade_prevista']].head()
```

---

### `predict_with_confidence(model, X, confidence=0.95)`

PrediÃ§Ãµes com intervalos de confianÃ§a (apenas para ensemble models).

**Exemplo:**
```python
from src.models.predict_model import predict_with_confidence

# Retorna: (predictions, lower_bound, upper_bound)
preds, lower, upper = predict_with_confidence(model, X_new, confidence=0.95)

df_new['pred'] = preds
df_new['pred_lower'] = lower
df_new['pred_upper'] = upper

# Visualizar incerteza
import plotly.graph_objects as go

fig = go.Figure([
    go.Scatter(y=df_new['quantidade'], name='Real'),
    go.Scatter(y=df_new['pred'], name='Previsto'),
    go.Scatter(y=df_new['pred_upper'], fill='tonexty', name='IC 95%'),
    go.Scatter(y=df_new['pred_lower'], fill='tonexty')
])
fig.show()
```

---

## Pipeline Completo ML

```python
import pandas as pd
from src.features.build_features import create_temporal_features, create_production_features
from src.models.train_model import train_production_model, save_model
from src.models.predict_model import predict_production
from src.logger import logger

# ========================================
# 1. FEATURE ENGINEERING
# ========================================
logger.info("ğŸ“Š Carregando dados...")
df = pd.read_parquet('data/02 - trusted/tb_tarefcon.parquet')

logger.info("ğŸ› ï¸ Criando features...")
df = create_temporal_features(df, 'dt_inicio')
df = create_production_features(df, group_cols=['cod_maquina'])

# Remover NaN dos lags
df = df.dropna()

logger.info(f"âœ… Features prontas: {df.shape}")

# ========================================
# 2. TRAIN/TEST SPLIT
# ========================================
# DivisÃ£o temporal (Ãºltimos 20% para teste)
split_idx = int(len(df) * 0.8)
df_train = df.iloc[:split_idx]
df_test = df.iloc[split_idx:]

logger.info(f"ğŸ“š Train: {len(df_train)} | Test: {len(df_test)}")

# ========================================
# 3. PREPARAR X e y
# ========================================
feature_cols = [
    'quantidade_lag_1', 'quantidade_lag_7', 'quantidade_lag_30',
    'quantidade_rolling_7d_mean', 'quantidade_rolling_7d_std',
    'year', 'month', 'day_of_week', 'is_weekend'
]

X_train = df_train[feature_cols]
y_train = df_train['quantidade']

X_test = df_test[feature_cols]
y_test = df_test['quantidade']

# ========================================
# 4. TREINAR MODELO
# ========================================
logger.info("ğŸ“ Treinando modelo...")
model, metrics = train_production_model(
    X_train, y_train,
    model_type='xgboost',
    n_estimators=200,
    max_depth=8,
    learning_rate=0.05,
    random_state=42
)

logger.info(f"âœ… MAE: {metrics['mae']:.2f}")
logger.info(f"âœ… RMSE: {metrics['rmse']:.2f}")
logger.info(f"âœ… RÂ²: {metrics['r2']:.3f}")

# ========================================
# 5. SALVAR MODELO
# ========================================
metadata = {
    'model_type': 'xgboost',
    'features': feature_cols,
    'metrics': metrics,
    'trained_at': pd.Timestamp.now().isoformat()
}
save_model(model, 'production_xgb_v1', metadata)

# ========================================
# 6. AVALIAR NO TEST SET
# ========================================
logger.info("ğŸ”® Avaliando no test set...")
y_pred = predict_production(model, X_test)

from sklearn.metrics import mean_absolute_error, r2_score
test_mae = mean_absolute_error(y_test, y_pred)
test_r2 = r2_score(y_test, y_pred)

logger.info(f"ğŸ“Š Test MAE: {test_mae:.2f}")
logger.info(f"ğŸ“Š Test RÂ²: {test_r2:.3f}")

# ========================================
# 7. SALVAR PREDIÃ‡Ã•ES
# ========================================
df_test['quantidade_prevista'] = y_pred
df_test.to_parquet('data/04 - refined/predicoes_teste.parquet')

logger.info("âœ… Pipeline ML concluÃ­do!")
```

---

## MÃ©tricas de AvaliaÃ§Ã£o

### RegressÃ£o

| MÃ©trica | FÃ³rmula | InterpretaÃ§Ã£o |
|---------|---------|---------------|
| **MAE** | `mean(|y - Å·|)` | Erro mÃ©dio absoluto (mesma unidade de y) |
| **RMSE** | `sqrt(mean((y - Å·)Â²))` | Erro mÃ©dio quadrÃ¡tico (penaliza outliers) |
| **RÂ²** | `1 - SS_res/SS_tot` | Percentual de variÃ¢ncia explicada (0-1) |
| **MAPE** | `mean(|y - Å·| / y) * 100` | Erro percentual mÃ©dio |

**Exemplo de interpretaÃ§Ã£o:**
```
MAE: 150   â†’ Erro mÃ©dio de 150 unidades
RMSE: 200  â†’ Erro tÃ­pico de 200 unidades (alguns erros maiores)
RÂ²: 0.85   â†’ Modelo explica 85% da variÃ¢ncia
MAPE: 12%  â†’ Erro mÃ©dio de 12%
```

---

## Feature Importance

```python
import pandas as pd
import plotly.express as px

# Obter importÃ¢ncias
importances = model.feature_importances_
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': importances
}).sort_values('importance', ascending=False)

# Plotar
fig = px.bar(
    feature_importance,
    x='importance',
    y='feature',
    orientation='h',
    title='Feature Importance'
)
fig.show()

# Top 5 features
print(feature_importance.head())
```

---

## Boas PrÃ¡ticas

### ğŸ¯ Modelagem
- âœ… DivisÃ£o temporal (nÃ£o aleatÃ³ria) para time series
- âœ… ValidaÃ§Ã£o cruzada (k-fold ou time series split)
- âœ… Tuning de hiperparÃ¢metros (GridSearch, Optuna)
- âœ… Ensemble de modelos (mÃ©dia de prediÃ§Ãµes)

### ğŸ“Š Monitoramento
- âœ… Salvar mÃ©tricas em cada treino
- âœ… Versionar modelos (production_v1, production_v2)
- âœ… Monitorar drift de features (distribuiÃ§Ãµes)
- âœ… A/B testing de modelos em produÃ§Ã£o

### ğŸ” ValidaÃ§Ã£o
- âœ… Analisar resÃ­duos (y - Å·)
- âœ… Checar overfitting (train vs test)
- âœ… Validar prediÃ§Ãµes (range, NaN)
- âœ… Interpretar feature importance

---

## Troubleshooting

### Erro: `ValueError: Input contains NaN`
**SoluÃ§Ã£o:** Remover NaN antes de treinar: `df.dropna()` ou `.fillna(0)`

### Erro: `ImportError: xgboost not found`
**SoluÃ§Ã£o:** Instalar: `pip install xgboost lightgbm`

### Modelo com RÂ² negativo
**SoluÃ§Ã£o:** Modelo pior que baseline. Revisar features e parÃ¢metros.

### Overfitting (train RÂ² >> test RÂ²)
**SoluÃ§Ã£o:**
- Reduzir `max_depth`
- Aumentar `min_samples_split`
- Adicionar regularizaÃ§Ã£o (L1/L2)
- Coletar mais dados
